{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the modules required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required modules\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:/Users/dhani/OneDrive/Desktop/BTP/Project Code/datasets/dataset_100ms.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path) as dataset_file:\n",
    "    dataset = json.loads(dataset_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"events\"][\"PAPI_L3_TCM\"][\"mysqld_node\"][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[\"events\"][\"PAPI_L3_TCM\"][\"mysqld_node\"][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"events\"][\"PAPI_L3_TCM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TCM = []\n",
    "for process_type in dataset[\"events\"][\"PAPI_L3_TCM\"]:\n",
    "    temp = dataset[\"events\"][\"PAPI_L3_TCM\"][process_type][\"data\"]\n",
    "    Sum = sum(temp)\n",
    "    data_TCM.append(Sum/len(temp))\n",
    "\n",
    "\n",
    "data_TCA = []\n",
    "for process_type in dataset[\"events\"][\"PAPI_L3_TCA\"]:\n",
    "    temp = dataset[\"events\"][\"PAPI_L3_TCA\"][process_type][\"data\"]\n",
    "    Sum = sum(temp)\n",
    "    data_TCA.append(Sum/len(temp))\n",
    "\n",
    "\n",
    "data_INS = []\n",
    "for process_type in dataset[\"events\"][\"PAPI_TOT_INS\"]:\n",
    "    temp = dataset[\"events\"][\"PAPI_TOT_INS\"][process_type][\"data\"]\n",
    "    Sum = sum(temp)\n",
    "    data_INS.append(Sum/len(temp))\n",
    "\n",
    "for process_type in dataset[\"events\"][\"PAPI_L3_TCM\"]:\n",
    "    labels.append(dataset[\"events\"][\"PAPI_L3_TCM\"][process_type][\"label\"])\n",
    "\n",
    "\n",
    "\n",
    "# data_TCM = []\n",
    "# for process_type in dataset[\"events\"][\"PAPI_L3_TCM\"]:\n",
    "#     temp = dataset[\"events\"][\"PAPI_L3_TCM\"][process_type][\"data\"]\n",
    "#     Sum = sum(temp)\n",
    "#     data_TCM.append(Sum)\n",
    "\n",
    "\n",
    "# data_TCA = []\n",
    "# for process_type in dataset[\"events\"][\"PAPI_L3_TCA\"]:\n",
    "#     temp = dataset[\"events\"][\"PAPI_L3_TCA\"][process_type][\"data\"]\n",
    "#     Sum = sum(temp)\n",
    "#     data_TCA.append(Sum)\n",
    "\n",
    "\n",
    "# data_INS = []\n",
    "# for process_type in dataset[\"events\"][\"PAPI_TOT_INS\"]:\n",
    "#     temp = dataset[\"events\"][\"PAPI_TOT_INS\"][process_type][\"data\"]\n",
    "#     Sum = sum(temp)\n",
    "#     data_INS.append(Sum)\n",
    "\n",
    "# for process_type in dataset[\"events\"][\"PAPI_L3_TCM\"]:\n",
    "#     labels.append(dataset[\"events\"][\"PAPI_L3_TCM\"][process_type][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[152.75209380234506,\n",
       " 0.0,\n",
       " 12068867.458961474,\n",
       " 47754980.15242881,\n",
       " 38614.077051926295,\n",
       " 0.0,\n",
       " 29619.177554438862,\n",
       " 54734.14237855947,\n",
       " 40463.38358458962,\n",
       " 26603.053601340034,\n",
       " 144044.02680067002,\n",
       " 32239.331658291456,\n",
       " 696.4556113902847,\n",
       " 65584.89782244556,\n",
       " 47761587.70686767,\n",
       " 17258079.701974865,\n",
       " 961952263.7863106,\n",
       " 12094026.851419032,\n",
       " 446520039.63342696,\n",
       " 918000625.6275862,\n",
       " 4405810.385642738,\n",
       " 6200075.98163606,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 62496179.83472454,\n",
       " 0.0,\n",
       " 62976561.32721202,\n",
       " 7.300500834724541,\n",
       " 227017471.2909699,\n",
       " 63.785953177257525,\n",
       " 1141791993.3283334,\n",
       " 104230678.9699115,\n",
       " 5957367.559265442]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_TCM\n",
    "data_TCA\n",
    "data_INS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[80.17755443886097, 126.25963149078727, 152.75209380234506],\n",
       " [0.0, 0.0, 0.0],\n",
       " [125757.13065326633, 722461.4556113903, 12068867.458961474],\n",
       " [487376.4070351759, 2848157.6247906196, 47754980.15242881],\n",
       " [11177.949748743718, 18822.58961474037, 38614.077051926295],\n",
       " [0.0, 0.0, 0.0],\n",
       " [3514.8525963149077, 9619.658291457286, 29619.177554438862],\n",
       " [6303.932998324958, 17431.524288107204, 54734.14237855947],\n",
       " [4760.371859296482, 12969.480737018426, 40463.38358458962],\n",
       " [3105.5159128978225, 8374.552763819096, 26603.053601340034],\n",
       " [16492.48743718593, 46283.0703517588, 144044.02680067002],\n",
       " [3783.742043551089, 10416.680067001675, 32239.331658291456],\n",
       " [113.8425460636516, 198.84757118927973, 696.4556113902847],\n",
       " [7441.006700167504, 21263.003350083753, 65584.89782244556],\n",
       " [489418.0854271357, 2832096.9128978224, 47761587.70686767],\n",
       " [173741.45601436266, 1290544.7145421903, 17258079.701974865],\n",
       " [1543.524207011686, 1670.0734557595993, 961952263.7863106],\n",
       " [101415.8263772955, 700914.1302170284, 12094026.851419032],\n",
       " [2337820.783707865, 30711303.39466292, 446520039.63342696],\n",
       " [3748264.4448275864, 8499803.648275862, 918000625.6275862],\n",
       " [8573.450751252087, 972756.0884808013, 4405810.385642738],\n",
       " [303385.9883138564, 818990.3539232053, 6200075.98163606],\n",
       " [0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0],\n",
       " [909314.202003339, 2243271.9148580967, 62496179.83472454],\n",
       " [0.0, 0.0, 0.0],\n",
       " [1290946.8247078464, 4268529.864774625, 62976561.32721202],\n",
       " [116.43572621035058, 134.26210350584307, 7.300500834724541],\n",
       " [1773863.9214046823, 11397103.618729098, 227017471.2909699],\n",
       " [18.55685618729097, 31.255852842809364, 63.785953177257525],\n",
       " [6699475.28, 9753352.721666666, 1141791993.3283334],\n",
       " [782793.2814159292, 1018284.7522123894, 104230678.9699115],\n",
       " [1189894.6043405677, 1443289.6661101836, 5957367.559265442]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(data_TCA)):\n",
    "    data.append([data_TCM[i],data_TCA[i],data_INS[i]])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled_data = []\n",
    "# shuffled_labels = []\n",
    "# indexes = list(range(len(data)))\n",
    "# shuffle(indexes)\n",
    "\n",
    "# for index in indexes:\n",
    "#     shuffled_data.append(data[index])\n",
    "#     shuffled_labels.append(labels[index])\n",
    "\n",
    "\n",
    "# data = shuffled_data\n",
    "# labels = shuffled_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.01775544e+01, 1.26259631e+02, 1.52752094e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.25757131e+05, 7.22461456e+05, 1.20688675e+07],\n",
       "       [4.87376407e+05, 2.84815762e+06, 4.77549802e+07],\n",
       "       [1.11779497e+04, 1.88225896e+04, 3.86140771e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.51485260e+03, 9.61965829e+03, 2.96191776e+04],\n",
       "       [6.30393300e+03, 1.74315243e+04, 5.47341424e+04],\n",
       "       [4.76037186e+03, 1.29694807e+04, 4.04633836e+04],\n",
       "       [3.10551591e+03, 8.37455276e+03, 2.66030536e+04],\n",
       "       [1.64924874e+04, 4.62830704e+04, 1.44044027e+05],\n",
       "       [3.78374204e+03, 1.04166801e+04, 3.22393317e+04],\n",
       "       [1.13842546e+02, 1.98847571e+02, 6.96455611e+02],\n",
       "       [7.44100670e+03, 2.12630034e+04, 6.55848978e+04],\n",
       "       [4.89418085e+05, 2.83209691e+06, 4.77615877e+07],\n",
       "       [1.73741456e+05, 1.29054471e+06, 1.72580797e+07],\n",
       "       [1.54352421e+03, 1.67007346e+03, 9.61952264e+08],\n",
       "       [1.01415826e+05, 7.00914130e+05, 1.20940269e+07],\n",
       "       [2.33782078e+06, 3.07113034e+07, 4.46520040e+08],\n",
       "       [3.74826444e+06, 8.49980365e+06, 9.18000626e+08],\n",
       "       [8.57345075e+03, 9.72756088e+05, 4.40581039e+06],\n",
       "       [3.03385988e+05, 8.18990354e+05, 6.20007598e+06],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [9.09314202e+05, 2.24327191e+06, 6.24961798e+07],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.29094682e+06, 4.26852986e+06, 6.29765613e+07],\n",
       "       [1.16435726e+02, 1.34262104e+02, 7.30050083e+00],\n",
       "       [1.77386392e+06, 1.13971036e+07, 2.27017471e+08],\n",
       "       [1.85568562e+01, 3.12558528e+01, 6.37859532e+01],\n",
       "       [6.69947528e+06, 9.75335272e+06, 1.14179199e+09],\n",
       "       [7.82793281e+05, 1.01828475e+06, 1.04230679e+08],\n",
       "       [1.18989460e+06, 1.44328967e+06, 5.95736756e+06]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = np.array(data)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Data[0])\n",
    "type(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46027499, -0.41909594, -0.42115094],\n",
       "       [-0.46033446, -0.41911785, -0.42115146],\n",
       "       [-0.36705638, -0.29369411, -0.38002952],\n",
       "       [-0.0988318 ,  0.0753398 , -0.25843714],\n",
       "       [-0.45204342, -0.41585014, -0.4210199 ],\n",
       "       [-0.46033446, -0.41911785, -0.42115146],\n",
       "       [-0.45772738, -0.41744782, -0.42105054],\n",
       "       [-0.45565863, -0.41609164, -0.42096497],\n",
       "       [-0.45680354, -0.41686627, -0.42101359],\n",
       "       [-0.458031  , -0.41766398, -0.42106082],\n",
       "       [-0.44810146, -0.41108283, -0.42066067],\n",
       "       [-0.45752794, -0.41730946, -0.42104162],\n",
       "       [-0.46025002, -0.41908333, -0.42114909],\n",
       "       [-0.45481523, -0.41542647, -0.420928  ],\n",
       "       [-0.09731742,  0.07255156, -0.25841462],\n",
       "       [-0.33146487, -0.19507137, -0.36234845],\n",
       "       [-0.45918958, -0.41882792,  2.85648399],\n",
       "       [-0.3851111 , -0.29743486, -0.37994379],\n",
       "       [ 1.27370196,  4.91255305,  1.1002649 ],\n",
       "       [ 2.31987312,  1.05650026,  2.70672869],\n",
       "       [-0.45397526, -0.25024142, -0.40613966],\n",
       "       [-0.23530338, -0.2769361 , -0.4000261 ],\n",
       "       [-0.46033446, -0.41911785, -0.42115146],\n",
       "       [-0.46033446, -0.41911785, -0.42115146],\n",
       "       [ 0.21413295, -0.02967207, -0.20820982],\n",
       "       [-0.46033446, -0.41911785, -0.42115146],\n",
       "       [ 0.49720207,  0.32192515, -0.20657303],\n",
       "       [-0.4602481 , -0.41909455, -0.42115144],\n",
       "       [ 0.85539712,  1.55948933,  0.35235939],\n",
       "       [-0.4603207 , -0.41911243, -0.42115125],\n",
       "       [ 4.50888055,  1.27412408,  3.46924732],\n",
       "       [ 0.12028834, -0.24233737, -0.06600893],\n",
       "       [ 0.42224841, -0.1685539 , -0.40085308]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaled_data = StandardScaler().fit_transform(Data)\n",
    "Scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Data to Training and testing Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(Scaled_data),np.array(labels), test_size=0.33, random_state=142,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the requied modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(40, activation='relu', input_dim=3))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 40)                160       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7197 - binary_accuracy: 0.2105 - val_loss: 0.7449 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7153 - binary_accuracy: 0.2105 - val_loss: 0.7395 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7110 - binary_accuracy: 0.2105 - val_loss: 0.7342 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7067 - binary_accuracy: 0.2105 - val_loss: 0.7289 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7025 - binary_accuracy: 0.2105 - val_loss: 0.7236 - val_binary_accuracy: 0.3333\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6983 - binary_accuracy: 0.2105 - val_loss: 0.7184 - val_binary_accuracy: 0.3333\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6941 - binary_accuracy: 0.2105 - val_loss: 0.7132 - val_binary_accuracy: 0.3333\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6900 - binary_accuracy: 0.2105 - val_loss: 0.7081 - val_binary_accuracy: 0.3333\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6859 - binary_accuracy: 0.2105 - val_loss: 0.7031 - val_binary_accuracy: 0.3333\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6819 - binary_accuracy: 0.2105 - val_loss: 0.6981 - val_binary_accuracy: 0.3333\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6779 - binary_accuracy: 0.2105 - val_loss: 0.6931 - val_binary_accuracy: 0.3333\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6739 - binary_accuracy: 0.3158 - val_loss: 0.6882 - val_binary_accuracy: 0.3333\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6700 - binary_accuracy: 0.4211 - val_loss: 0.6834 - val_binary_accuracy: 0.3333\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6661 - binary_accuracy: 0.4211 - val_loss: 0.6786 - val_binary_accuracy: 0.3333\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6623 - binary_accuracy: 0.6316 - val_loss: 0.6739 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6585 - binary_accuracy: 0.8421 - val_loss: 0.6693 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6547 - binary_accuracy: 0.8421 - val_loss: 0.6648 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6510 - binary_accuracy: 0.8421 - val_loss: 0.6602 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6473 - binary_accuracy: 0.8421 - val_loss: 0.6558 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6437 - binary_accuracy: 0.8421 - val_loss: 0.6513 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6401 - binary_accuracy: 0.8421 - val_loss: 0.6470 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6365 - binary_accuracy: 0.8421 - val_loss: 0.6426 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6329 - binary_accuracy: 0.8421 - val_loss: 0.6383 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6294 - binary_accuracy: 0.8421 - val_loss: 0.6340 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6260 - binary_accuracy: 0.8421 - val_loss: 0.6298 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6225 - binary_accuracy: 0.8421 - val_loss: 0.6257 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6191 - binary_accuracy: 0.8421 - val_loss: 0.6216 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6158 - binary_accuracy: 0.8421 - val_loss: 0.6175 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6124 - binary_accuracy: 0.8421 - val_loss: 0.6135 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6091 - binary_accuracy: 0.8421 - val_loss: 0.6095 - val_binary_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6059 - binary_accuracy: 0.8421 - val_loss: 0.6056 - val_binary_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6027 - binary_accuracy: 0.8421"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6027 - binary_accuracy: 0.8421 - val_loss: 0.6017 - val_binary_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5995 - binary_accuracy: 0.8421 - val_loss: 0.5978 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5963 - binary_accuracy: 0.8421 - val_loss: 0.5940 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5932 - binary_accuracy: 0.8421 - val_loss: 0.5902 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5901 - binary_accuracy: 0.8421 - val_loss: 0.5864 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5871 - binary_accuracy: 0.8421 - val_loss: 0.5827 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5841 - binary_accuracy: 0.8421 - val_loss: 0.5790 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5811 - binary_accuracy: 0.8421"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model1.fit(X_train, np.array(y_train), validation_split=.1, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 150ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.predict([np.array(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.01921572],\n",
       "        [0.01891708],\n",
       "        [0.01897206],\n",
       "        [0.01891708],\n",
       "        [0.05146989],\n",
       "        [0.01891708],\n",
       "        [0.01891823],\n",
       "        [0.01903   ],\n",
       "        [0.05244165],\n",
       "        [0.01897964],\n",
       "        [0.02645463]], dtype=float32),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(predictions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predictions:\n",
    "    i[0] = i[0]*10\n",
    "\n",
    "for i in predictions:\n",
    "    if i[0]>0.5:\n",
    "        i[0]=1\n",
    "    else:\n",
    "        i[0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 1],\n",
       "       [1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, predictions)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGdCAYAAACPX3D5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApoElEQVR4nO3de3xU1bn/8e8kkAkXiUBggjEQLgJykIQmJARrj9ZorFZFq0arDeZYahWpMNVKvBDBy3A7mGKCsRxSUWxJ9YiiUtCOWkWi4RcMeAWRS7wwA1EECScTM8nvD9ro7AScCRMnuD5vXvv1Kmv2XnvtqcM88zxr7W1rbm5uFgAAMFZUpAcAAAAii2AAAADDEQwAAGA4ggEAAAxHMAAAgOEIBgAAMBzBAAAAhiMYAADAcAQDAAAYrkukB/Bv3cbeFOkhAJ3Ovg3FkR4C0CnFdvC3Vzi/k/7vrc7/Oe40wQAAAJ2GzazEuVlXCwAAWiEzAACAlc0W6RF8rwgGAACwMqxMQDAAAICVYZkBs0IfAADQCpkBAACsKBMAAGA4ygQAAMAkZAYAALAyrExg1tUCABAMmy18W4hKSkqUnJys2NhYZWZmqrKy8oj7nnnmmbLZbK22Cy64IKRzEgwAANBJlJeXy+l0qrCwUBs3blRKSopycnK0Z8+eNvd/6qmntHv37pbtnXfeUXR0tC6//PKQzkswAACAlS0qfFsIFi5cqMmTJys/P1+jRo1SaWmpunfvrrKysjb379OnjxISElq2F198Ud27dycYAADgmEWgTNDQ0KCqqiplZ2e3tEVFRSk7O1sVFRVB9bF06VJdeeWV6tGjR0iXywRCAAA6kM/nk8/nC2iz2+2y2+0BbbW1tfL7/XI4HAHtDodDH3zwwXeep7KyUu+8846WLl0a8hjJDAAAYBXGMoHL5VJcXFzA5nK5wj7kpUuX6rTTTlNGRkbIx5IZAADAKow3HSooKJDT6Qxos2YFJCk+Pl7R0dHyer0B7V6vVwkJCUc9R11dnVasWKHZs2e3a4xkBgAAsApjZsBut6tXr14BW1vBQExMjNLS0uR2u1vampqa5Ha7lZWVddThPvHEE/L5fLrmmmvadblkBgAA6CScTqcmTZqk9PR0ZWRkqKioSHV1dcrPz5ck5eXlKTExsVWZYenSpZo4caL69u3brvMSDAAAYBWhOxDm5uZq7969mjlzpjwej1JTU7VmzZqWSYU1NTWKigoc25YtW7Ru3Tq98MIL7T6vrbm5ufmYRh4m3cbeFOkhAJ3Ovg3FkR4C0CnFdvBP2W5n3RO2vv7v5bvC1ldHYc4AAACGo0wAAICVYQ8qIhgAAMAqjEsLjwdmhT4AAKAVMgMAAFhRJgAAwHCUCQAAgEnIDAAAYEWZAAAAwxlWJiAYAADAyrDMgFlXCwAAWiEzAACAFWUCAAAMR5kAAACYhMwAAABWlAkAADAcZQIAAGASMgMAAFgZlhkgGAAAwMqwOQNmhT4AAKAVMgMAAFhRJgAAwHCGlQkIBgAAsDIsM2DW1QIAgFbIDAAAYEWZAAAAs9kMCwYoEwAAYDgyAwAAWJiWGSAYAADAyqxYgDIBAACmIzMAAIAFZQIAAAxnWjBAmQAAAMORGQAAwMK0zADBAAAAFgQDAACYzqxYgDkDAACYjswAAAAWlAkAADCcacEAZQIAAAxHZgAAAAvTMgMEAwAAWJgWDFAmAADAcGQGAACwMisxQDAAAIAVZQIAAGAUMgMAAFiQGQAAwHA2my1sW6hKSkqUnJys2NhYZWZmqrKy8qj7f/nll5oyZYoGDBggu92u4cOHa/Xq1SGdk8wAAABWEUoMlJeXy+l0qrS0VJmZmSoqKlJOTo62bNmi/v37t9q/oaFB55xzjvr3768nn3xSiYmJ2rVrl0488cSQzkswAABAJ7Fw4UJNnjxZ+fn5kqTS0lI9//zzKisr04wZM1rtX1ZWpi+++ELr169X165dJUnJyckhn5cyAQAAFpEoEzQ0NKiqqkrZ2dktbVFRUcrOzlZFRUWbx6xatUpZWVmaMmWKHA6HRo8erfvvv19+vz+k6yUzAACARTgnEPp8Pvl8voA2u90uu90e0FZbWyu/3y+HwxHQ7nA49MEHH7TZ9/bt2/XSSy/p6quv1urVq7Vt2zbdeOON+vrrr1VYWBj0GMkMAADQgVwul+Li4gI2l8sVlr6bmprUv39//elPf1JaWppyc3N1xx13qLS0NKR+yAwAAGARzsxAQUGBnE5nQJs1KyBJ8fHxio6OltfrDWj3er1KSEhos+8BAwaoa9euio6Obmk79dRT5fF41NDQoJiYmKDGSGYAAACLcM4ZsNvt6tWrV8DWVjAQExOjtLQ0ud3ulrampia53W5lZWW1Oc7TTz9d27ZtU1NTU0vb1q1bNWDAgKADAYlgAACATsPpdGrJkiVatmyZ3n//fd1www2qq6trWV2Ql5engoKClv1vuOEGffHFF7r55pu1detWPf/887r//vs1ZcqUkM5LmQAAAKsI3WcgNzdXe/fu1cyZM+XxeJSamqo1a9a0TCqsqalRVNQ3v+OTkpK0du1aTZ8+XWPGjFFiYqJuvvlm3XbbbSGd19bc3Nwc1itpp25jb4r0EIBOZ9+G4kgPAeiUYjv4p2ziDSvD1tenD10Str46CmUCAAAMR5kAAAAL0x5URDAAAIAFwQAAAKYzKxZgzgAAAKYjMwAAgAVlAnRqHzw/S4NO6tuqvbT8Vc1e/JzuuuECnT1+pJISeqt230E9+8pmzVr8nA4crD9in//3VtvL125/YKUeePTwnbCeKLpeKcMT1a/PCdp34JBefnOL7lz0jHbv3S9JGjigj5bem6expybprfc/1nV3Pqqa3V+09PW/f/ytHlv1hp52Vx/D1QPBq6s7qJJFf9RL7n/oiy8+18hTR+kPM27X6NPGHPGYDZVvasG8Ofpo24dKSBigydffoIsvuTSkPpf9ean+XPY/kqT86yZr0rX/1fLa5s2bdP89s7T8r39Tly7889uZEQygU/vxNfMVHfXNf6Sjhp2k1aVT9dSLb2lAvzgN6BenggdW6v3tHg0c0EcP3nGlBvSL0y9vXXrEPpOzCwL+fu7p/6HSwl9q5be+uF/dsFXzl66Vp3a/Tup/olzTL9Ff5l+ns65dKEma+/tL9dmeL/XbWY/r7ht/rjnOS1rOedm5P1JTczOBAL5Xd8+8U9s+/FD3zZmnfv366/nnVun6X+frqVWrWz0VTpI++eRj3XTj9br8iivlmrtAb75RoVmFdyq+Xz+d/uMzgupz65YPtLh4kRaVHH5IzNQbr9eECafrlOEj1NjYqHtnFWrm3bMJBNDpMGfgOFO776C8n3/Vsp1/xmh9VLNXr1V9qPc+2q2rbvkfrX71He34pFb/3LBVdxc/q/N/MlrR0Uf+v/rb/Xk//0oXnnma/rnhQ+389POWfR58/GVVvr1TNbv36Y1NO7Tgzy8q47RkdelyuN8Rgx1a/uyb+qhmrx579k2NGHz4oRpxPbupcMrPNd1V3rFvDPAt9fX1cr/4gqb//lalpY/TwEGDdMOUqUoaOEhPrPhLm8c8Ub5CiYkn65Y/zNCQoUN11dXXKPvcHC1/9JGg+9yxY7tOGT5CmeOzlDk+S6cMH6EdO7ZLOpwxSEtPP2pmAp1HOJ9NcDwgGDiOde0SrSvPH6dlz1QccZ9eJ8TqQF29/P6mI+7zbf37nKDzfjxay54+cp+9e3XXlT9L1xubdqix8XC/b2/9VD/NHCmbzabs8SP1zoefSpLunz5RD5e/qk+8XwZ/YcAx8vsb5ff7Wz0Mxm636623NrZ5zOZN1Ro/PvBhMBNO/7E2b6oOus9TThmhXTt3avdnn+mzzz7Vrl07NWzYcH1cU6OnVz6lm343LTwXiA5nWjAQcq6qtrZWZWVlqqiokMfjkSQlJCRowoQJuvbaa9WvX7+wDxJtu+isMTrxhG5a/uybbb7e98QeKpj8M5X97/qg+7zmwkx9daheT79U3eq1e393sX575U/Uo5tdb27eoUt/983zsgsWrtSDd16lLc/P0tsffqap9/5Vp/9oqFJGnKw7//iMls/9L/1o1ED9440P9Pu5T+jrRn/I1wsEq0ePnkpJHas/lS7W4CFD1LdvvP6++jlt3lStpIED2zymtrZWfePjA9r69o3XwYMHVV9fH1SfQ4YO1dRp03X95MMPlfndNKeGDB2q31x3rab//latX7dODy0uVpcuXXRbwR1KSx/XsW8EEKSQgoENGzYoJydH3bt3V3Z2toYPHy7p8LOWFy1apDlz5mjt2rVKT08/aj8+n08+ny+grbnJL1tU9BGOQFsmTZygta+/1zKJ79tO6BGrlYtu0Pvbd+veh58Pus+8i8er/O//T76GxlavPfDoP/TI0xUaOKCP7rj+Z/qfe37VEhB8tne/fnHzN8FBTNcuWrV4iibPfEwzJp+nrw7Va8wls7WqeIp+fdmP9dCKf7bjioHg3eeap8K7btc5Z/1E0dHRGnnqKJ13/gV6/713O7TPK3Kv0hW5V7X8fdXTK9W9Rw+lpKTq4p+fp8fLn5TX49Ftt0zX6hdeCukxs/geHR8/6MMmpGBg6tSpuvzyy1VaWtoq9dHc3Kzf/va3mjp1qioqjpxiliSXy6VZs2YFtEU7xqnrgIxQhmO0gQN666eZI3TlLUtavdazu12rSm7UV4fqletc0pLK/y6njx2qEYMT9KsZf27z9c+/rNPnX9ZpW80ebdnh0ba19ypzzGC9uXlHq33/cN25cr/xgd56/2OV3PVLzVr8rBobm/TMS5t0ZsZwggF0uKSBA1W2bLkOHTqkurqD6tevv279/TSdfHJSm/vHx8fr89ragLbPP69Vz549FRsb264+9+37QqUPFevPyx7X25s3aeCgZA3619bY2KhdO3folOEjwnvhCIvjJb0fLiHNGdi0aZOmT5/e5ptks9k0ffp0VVdXf2c/BQUF2r9/f8DWxZEWylCM96uLsrTni6/099cCf+Wc0CNWzz10kxq+9uuyaQ+3+Qv/SCZNzFLVezV6e+un37lv1L9WNMR0bR1PjhjsUO7P0jWr5DlJUnS0TV27HM76dO0SFbAaAuho3bt3V79+/XVg/35VvL5OZ551dpv7jUlJ1ZtvvhHQ9sb69RqTktruPufPdemavGvlSEiQv6lJjY3ffB4b/f6g5/IAHS2kzEBCQoIqKys1cuTINl+vrKxsc8mOld1ubzUJhxJB8Gw2m/IuHq/Hn3sz4B+TE3rE6rnFU9QtNkb5dyxTrx6x6tXj8C+avfsOqqnp8NOqq5+6UzMfXKVVL28OOPbSc8ZqxsLWj+0cN3qQ0v5jkNa/9ZG+/OqQBp/cT4U3XqCPava2mRUoufMq/WHBUzpU3yBJqqjervxLTteHu/bolz/P1BNr/l9Y3w+gLa+ve01qbtagwYP1cU2NHlgwT8mDh7TcN+CPD/y39uzx6j7XPEnS5blXasVfH9cDC+Zp4qW/UOWbb+iFtX/Xg4sfDrrPb6tY/7p27dype++fK0kaPfo07dyxXete+6c8uz2KjopS8uDB38M7gfYwLTMQUjBwyy236De/+Y2qqqp09tlnt3zxe71eud1uLVmyRAsWLOiQgeIbP80coYED+mjZ04G/YlJHJiljzOF/XN579u6A10acP7PlJkAjBieoV89uAa9fnpMmm2z6Wxtf1Ifqv9bFP03Rnb+9QD26xchTu18vrH9fc5eUqeHrwMzDdb84/V8Zi3da2u4rXa1HXNfq1Udv0Yvr31fp315t97UDwTp48CstKloor8ejuLgTdfY552rqzdPVtWtXSVLt3r3y7N7dsv/JJyepePHDmj/XpceXPypHQoIKZ93bco+BYPr8t/r6ernum615C4oUFXU4AetISNCM2+/SzDtuV0xMjO65f25L+QGdj2GxgGzNzc3NoRxQXl6uBx54QFVVVfL7D88Ij46OVlpampxOp6644op2DaTb2JvadRzwQ7ZvQ9t3hwRMF9vB92065dY1Yevrw/nnha2vjhLy25mbm6vc3Fx9/fXXqv3XZJv4+PhWkTEAADg+tDu26tq1qwYMGBDOsQAA0CmYVibgBtkAAFiYNoGQ2xEDAGA4MgMAAFgYlhggGAAAwCrKsJujUSYAAMBwZAYAALCgTAAAgOFYTQAAAIxCZgAAAAvDEgMEAwAAWJlWJiAYAADAwrRggDkDAAAYjswAAAAWhiUGCAYAALCiTAAAAIxCZgAAAAvDEgMEAwAAWFEmAAAARiEzAACAhWGJAYIBAACsKBMAAACjkBkAAMDCsMQAwQAAAFamlQkIBgAAsDAsFmDOAAAApiMzAACABWUCAAAMZ1gsQJkAAADTkRkAAMDCtDIBmQEAACxstvBtoSopKVFycrJiY2OVmZmpysrKI+77yCOPyGazBWyxsbEhn5NgAACATqK8vFxOp1OFhYXauHGjUlJSlJOToz179hzxmF69emn37t0t265du0I+L8EAAAAW1l/bx7KFYuHChZo8ebLy8/M1atQolZaWqnv37iorKzvqWBMSElo2h8MR8vUSDAAAYBHOYMDn8+nAgQMBm8/na3XOhoYGVVVVKTs7u6UtKipK2dnZqqioOOJYDx48qEGDBikpKUkXX3yx3n333ZCvl2AAAIAO5HK5FBcXF7C5XK5W+9XW1srv97f6Ze9wOOTxeNrse8SIESorK9Mzzzyj5cuXq6mpSRMmTNAnn3wS0hhZTQAAgEU4FxMUFBTI6XQGtNnt9rD0nZWVpaysrJa/T5gwQaeeeqoefvhh3XPPPUH3QzAAAIBFOJcW2u32oL784+PjFR0dLa/XG9Du9XqVkJAQ1Lm6du2qsWPHatu2bSGNkTIBAAAWkVhaGBMTo7S0NLnd7pa2pqYmud3ugF//R+P3+/X2229rwIABIV0vmQEAADoJp9OpSZMmKT09XRkZGSoqKlJdXZ3y8/MlSXl5eUpMTGyZczB79myNHz9ew4YN05dffqn58+dr165d+vWvfx3SeQkGAACwiNQdCHNzc7V3717NnDlTHo9HqampWrNmTcukwpqaGkVFfZPU37dvnyZPniyPx6PevXsrLS1N69ev16hRo0I6r625ubk5rFfSTt3G3hTpIQCdzr4NxZEeAtApxXbwT9mzHzzyUr5QuacGl+KPJOYMAABgOMoEAABYRBn2oCKCAQAALAyLBSgTAABgOjIDAABYRGo1QaQQDAAAYBFlVixAMAAAgJVpmQHmDAAAYDgyAwAAWBiWGCAYAADAyiazogHKBAAAGI7MAAAAFqwmAADAcKwmAAAARiEzAACAhWGJAYIBAACsTHtqIWUCAAAMR2YAAAALwxIDBAMAAFiZtpqAYAAAAAvDYgHmDAAAYDoyAwAAWJi2moBgAAAAC7NCAcoEAAAYj8wAAAAWrCYAAMBwpj21kDIBAACGIzMAAIAFZQIAAAxnWCxAmQAAANORGQAAwIIyAQAAhjNtNQHBAAAAFqZlBpgzAACA4cgMAABgYVZegGAAAIBWTHtqIWUCAAAMR2YAAAALwxIDBAMAAFixmgAAABiFzAAAABaGJQYIBgAAsGI1AQAAMAqZAQAALAxLDBAMAABgZdpqgk4TDOzbUBzpIQAAIMm8Grpp1wsAACwIBgAAsLDZbGHbQlVSUqLk5GTFxsYqMzNTlZWVQR23YsUK2Ww2TZw4MeRzEgwAAGARZQvfFory8nI5nU4VFhZq48aNSklJUU5Ojvbs2XPU43bu3KlbbrlFZ5xxRvuut11HAQCAsFu4cKEmT56s/Px8jRo1SqWlperevbvKysqOeIzf79fVV1+tWbNmaciQIe06L8EAAAAW4cwM+Hw+HThwIGDz+XytztnQ0KCqqiplZ2d/M46oKGVnZ6uiouKIY509e7b69++v6667rv3X2+4jAQD4gQrnnAGXy6W4uLiAzeVytTpnbW2t/H6/HA5HQLvD4ZDH42lznOvWrdPSpUu1ZMmSY7reTrO0EACAH6KCggI5nc6ANrvdfsz9fvXVV/rVr36lJUuWKD4+/pj6IhgAAMAi1Il/R2O324P68o+Pj1d0dLS8Xm9Au9frVUJCQqv9P/roI+3cuVMXXnhhS1tTU5MkqUuXLtqyZYuGDh0a1BgpEwAAYGGzhW8LVkxMjNLS0uR2u1vampqa5Ha7lZWV1Wr/kSNH6u2331Z1dXXLdtFFF+mss85SdXW1kpKSgj43mQEAADoJp9OpSZMmKT09XRkZGSoqKlJdXZ3y8/MlSXl5eUpMTJTL5VJsbKxGjx4dcPyJJ54oSa3avwvBAAAAFpF6hHFubq727t2rmTNnyuPxKDU1VWvWrGmZVFhTU6OoqPAn9W3Nzc3NYe+1HeobIz0CAMDxIraDf8revnpr2Pq6//zhYeuro5AZAADAwrCHFjKBEAAA05EZAADAIlJzBiKFYAAAAAvDYgHKBAAAmI7MAAAAFuG8A+HxgGAAAAAL0+YMUCYAAMBwZAYAALAwLDFAMAAAgJVpcwYoEwAAYDgyAwAAWNhkVmqAYAAAAAvTygQEAwAAWJgWDDBnAAAAw5EZAADAwmbY2kKCAQAALCgTAAAAo5AZAADAwrAqAcEAAABWPKgIAAAYhcwAAAAWpk0gJBgAAMDCsCoBZQIAAExHZgAAAIsoHlQEAIDZTCsTEAwAAGBh2gRC5gwAAGA4MgMAAFiYdtMhggEAACwMiwUoEwAAYDoyAwAAWFAmAADAcIbFApQJAAAwHZkBAAAsTPulTDAAAICFzbA6gWnBDwAAsCAzAACAhVl5AYIBAABaYWkhAACGMysUYM4AAADGIzMAAICFYVUCggEAAKxYWggAAIxCZgAAAAvTfikTDAAAYEGZAAAAGIVgAAAAC1sYt1CVlJQoOTlZsbGxyszMVGVl5RH3feqpp5Senq4TTzxRPXr0UGpqqh577LGQz0kwAACAhc1mC9sWivLycjmdThUWFmrjxo1KSUlRTk6O9uzZ0+b+ffr00R133KGKigpt3rxZ+fn5ys/P19q1a0O73ubm5uaQjugg9Y2RHgEA4HgR28Ez3p7ctDtsfV2WMiDofTMzMzVu3DgVFxdLkpqampSUlKSpU6dqxowZQfXxox/9SBdccIHuueeeoM9LZgAAAIuoMG4+n08HDhwI2Hw+X6tzNjQ0qKqqStnZ2d+MIypK2dnZqqio+M4xNzc3y+12a8uWLfrJT34S8vUCAIBvCWeZwOVyKS4uLmBzuVytzllbWyu/3y+HwxHQ7nA45PF4jjjW/fv3q2fPnoqJidEFF1ygBx98UOecc05I18vSQgAALMK5sLCgoEBOpzOgzW63h63/E044QdXV1Tp48KDcbrecTqeGDBmiM888M+g+CAYAAOhAdrs9qC//+Ph4RUdHy+v1BrR7vV4lJCQc8bioqCgNGzZMkpSamqr3339fLpcrpGCAMgEAABY2W/i2YMXExCgtLU1ut7ulrampSW63W1lZWUH309TU1OachKMhMwAAgEVUWAsFwXM6nZo0aZLS09OVkZGhoqIi1dXVKT8/X5KUl5enxMTEljkHLpdL6enpGjp0qHw+n1avXq3HHntMDz30UEjnJRgAAKCTyM3N1d69ezVz5kx5PB6lpqZqzZo1LZMKa2pqFBX1TVK/rq5ON954oz755BN169ZNI0eO1PLly5WbmxvSebnPAADguNPR9xl47h3vd+8UpJ+Pdnz3ThFGZgAAAAtbhMoEkcIEQgAADEdmAAAAC8OeYEwwAACAVaRWE0QKZQIAAAxHZgAAAAvKBAAAGI5gAAAAw7G0EAAAGIXMAAAAFlFmJQYIBgAAsKJMAAAAjEJmAAAAC1YTAABgOMoEAADAKGQGAACwMG01AZmBH4C6uoOa57pP52WfpYwfjVHe1Vfqnbc3H/WYDZVvKveyS5SeOlo/P+8cPbPyqZD7XPbnpTrzjCydeUaWlj1SFvDa5s2bdOXll6qxsTE8FwmEiM8FjoUtjH+OBwQDPwB3z7xTFRXrdd+ceXpy5bPKmnC6rv91vrxeb5v7f/LJx7rpxus1LiNTf/vfZ3T1ryZpVuGden3da0H3uXXLB1pcvEhz5y/U3PkLVbKoSB9u3SJJamxs1L2zCnXnzLvVpQvJJ0QGnwsgeAQDx7n6+nq5X3xB039/q9LSx2ngoEG6YcpUJQ0cpCdW/KXNY54oX6HExJN1yx9maMjQobrq6muUfW6Olj/6SNB97tixXacMH6HM8VnKHJ+lU4aP0I4d2yUd/mWUlp6u0aeN+V7eA8CKzwWOlc0Wvu14QDBwnPP7G+X3+2W32wPa7Xa73nprY5vHbN5UrfHjswLaJpz+Y23eVB10n6ecMkK7du7U7s8+02effapdu3Zq2LDh+rimRk+vfEo3/W5aeC4QaAc+FzhWtjBuxwNyVce5Hj16KiV1rP5UuliDhwxR377x+vvq57R5U7WSBg5s85ja2lr1jY8PaOvbN14HDx5UfX19UH0OGTpUU6dN1/WT8yVJv5vm1JChQ/Wb667V9N/fqvXr1umhxcXq0qWLbiu4Q2np4zr2jQC+hc8FjlXU8fKTPkzCHgx8/PHHKiwsVFlZ2RH38fl88vl8AW3N0fZWETeCc59rngrvul3nnPUTRUdHa+Spo3Te+Rfo/ffe7dA+r8i9SlfkXtXy91VPr1T3Hj2UkpKqi39+nh4vf1Jej0e33TJdq194STExMcd0nUAo+FwAwQt7meCLL77QsmXLjrqPy+VSXFxcwDZ/rivcQzFG0sCBKlu2XBUb3tJa9yv6S/mTamxs1MknJ7W5f3x8vD6vrQ1o+/zzWvXs2VOxsbHt6nPfvi9U+lCxCm6/S29v3qSBg5I1aFCyMjLHq7GxUbt27gjvRQPfgc8FjgVlgu+watWqo76+ffv27+yjoKBATqczoK05mqzAserevbu6d++uA/v3q+L1dZrmvLXN/cakpGrda68GtL2xfr3GpKS2u8/5c126Ju9aORIS9M47bwcsnWr0++X3N7X/woBjwOcC7XK8fIuHScjBwMSJE2Wz2dTc3HzEfWzfUWux21uXBOpZdttur697TWpu1qDBg/VxTY0eWDBPyYOH6OJLLpUk/fGB/9aePV7d55onSbo890qt+OvjemDBPE289BeqfPMNvbD273pw8cNB9/ltFetf166dO3Xv/XMlSaNHn6adO7Zr3Wv/lGe3R9FRUUoePPh7eCeAb/C5AIIXcjAwYMAALV68WBdffHGbr1dXVystLe2YB4bgHTz4lRYVLZTX41Fc3Ik6+5xzNfXm6erataskqXbvXnl2727Z/+STk1S8+GHNn+vS48sflSMhQYWz7tXpPz4j6D7/rb6+Xq77ZmvegiJFRR2uOjkSEjTj9rs0847bFRMTo3vun9uSZgW+L3wucCyOl5sFhYut+Wg/8dtw0UUXKTU1VbNnz27z9U2bNmns2LFqagot/UVmAAAQrNgOXgtXuX1/2PrKGBIXtr46Sshv56233qq6urojvj5s2DC9/PLLxzQoAADw/Qk5M9BRyAwAAILV0ZmBDWHMDIz7IWYGAAD4wTNrygC3IwYAwHRkBgAAsDBtNQHBAAAAFoY9moBgAAAAK8NiAeYMAABgOjIDAABYGZYaIBgAAMDCtAmElAkAADAcmQEAACxYTQAAgOEMiwUoEwAAYDoyAwAAWBmWGiAYAADAgtUEAADAKGQGAACwYDUBAACGMywWIBgAAKAVw6IB5gwAANCJlJSUKDk5WbGxscrMzFRlZeUR912yZInOOOMM9e7dW71791Z2dvZR9z8SggEAACxsYfwTivLycjmdThUWFmrjxo1KSUlRTk6O9uzZ0+b+r7zyiq666iq9/PLLqqioUFJSks4991x9+umnoV1vc3Nzc0hHdJD6xkiPAABwvIjt4CL3e5/Vha2vUSf1CHrfzMxMjRs3TsXFxZKkpqYmJSUlaerUqZoxY8Z3Hu/3+9W7d28VFxcrLy8v6POSGQAAoAP5fD4dOHAgYPP5fK32a2hoUFVVlbKzs1vaoqKilJ2drYqKiqDOdejQIX399dfq06dPSGMkGAAAwMIWxs3lcikuLi5gc7lcrc5ZW1srv98vh8MR0O5wOOTxeIIa92233aaTTjopIKAIBqsJAACwCuNqgoKCAjmdzoA2u90evhP8y5w5c7RixQq98sorio2NDelYggEAADqQ3W4P6ss/Pj5e0dHR8nq9Ae1er1cJCQlHPXbBggWaM2eO/vGPf2jMmDEhj5EyAQAAFpFYTRATE6O0tDS53e6WtqamJrndbmVlZR3xuHnz5umee+7RmjVrlJ6e3q7rJTMAAIBFpG5H7HQ6NWnSJKWnpysjI0NFRUWqq6tTfn6+JCkvL0+JiYktcw7mzp2rmTNn6i9/+YuSk5Nb5hb07NlTPXv2DPq8BAMAAHQSubm52rt3r2bOnCmPx6PU1FStWbOmZVJhTU2NoqK+Seo/9NBDamho0GWXXRbQT2Fhoe6+++6gz8t9BgAAx52Ovs/AVs+hsPU1PKF72PrqKGQGAACwMuzZBAQDAABYhHob4eMdqwkAADAcmQEAACwitZogUggGAACwMCwWoEwAAIDpyAwAAGBlWGqAYAAAAAtWEwAAAKOQGQAAwILVBAAAGM6wWIAyAQAApiMzAACAlWGpAYIBAAAsTFtNQDAAAICFaRMImTMAAIDhyAwAAGBhWGKAYAAAACvKBAAAwChkBgAAaMWs1ADBAAAAFpQJAACAUcgMAABgYVhigGAAAAArygQAAMAoZAYAALDg2QQAAJjOrFiAYAAAACvDYgHmDAAAYDoyAwAAWJi2moBgAAAAC9MmEFImAADAcGQGAACwMisxQDAAAICVYbEAZQIAAExHZgAAAAtWEwAAYDhWEwAAAKOQGQAAwMK0MgGZAQAADEdmAAAACzIDAADAKGQGAACwMG01AcEAAAAWlAkAAIBRyAwAAGBhWGKAYAAAgFYMiwYoEwAA0ImUlJQoOTlZsbGxyszMVGVl5RH3fffdd/WLX/xCycnJstlsKioqatc5CQYAALCwhfFPKMrLy+V0OlVYWKiNGzcqJSVFOTk52rNnT5v7Hzp0SEOGDNGcOXOUkJDQ/uttbm5ubvfRYVTfGOkRAACOF7EdXOSuawjfV2OPmOADgszMTI0bN07FxcWSpKamJiUlJWnq1KmaMWPGUY9NTk7WtGnTNG3atJDHSGYAAIAO5PP5dODAgYDN5/O12q+hoUFVVVXKzs5uaYuKilJ2drYqKio6dIwEAwAAWNjCuLlcLsXFxQVsLper1Tlra2vl9/vlcDgC2h0OhzweT4dc57+xmgAAAKswriYoKCiQ0+kMaLPb7eE7QRgQDAAAYBHO2xHb7fagvvzj4+MVHR0tr9cb0O71eo9pcmAwKBMAANAJxMTEKC0tTW63u6WtqalJbrdbWVlZHXpuMgMAAFhE6tkETqdTkyZNUnp6ujIyMlRUVKS6ujrl5+dLkvLy8pSYmNgy56ChoUHvvfdey//+9NNPVV1drZ49e2rYsGFBn7fTLC1E5+Dz+eRyuVRQUNDpalpApPC5wPepuLhY8+fPl8fjUWpqqhYtWqTMzExJ0plnnqnk5GQ98sgjkqSdO3dq8ODBrfr4z//8T73yyitBn5NgAAEOHDiguLg47d+/X7169Yr0cIBOgc8FfuiYMwAAgOEIBgAAMBzBAAAAhiMYQAC73a7CwkImSQHfwucCP3RMIAQAwHBkBgAAMBzBAAAAhiMYAADAcAQDAAAYjmAALUpKSpScnKzY2FhlZmaqsrIy0kMCIurVV1/VhRdeqJNOOkk2m01PP/10pIcEdAiCAUiSysvL5XQ6VVhYqI0bNyolJUU5OTnas2dPpIcGRExdXZ1SUlJUUlIS6aEAHYqlhZAkZWZmaty4cSouLpZ0+LGZSUlJmjp1qmbMmBHh0QGRZ7PZtHLlSk2cODHSQwHCjswA1NDQoKqqKmVnZ7e0RUVFKTs7WxUVFREcGQDg+0AwANXW1srv98vhcAS0OxwOeTyeCI0KAPB9IRgAAMBwBANQfHy8oqOj5fV6A9q9Xq8SEhIiNCoAwPeFYACKiYlRWlqa3G53S1tTU5PcbreysrIiODIAwPehS6QHgM7B6XRq0qRJSk9PV0ZGhoqKilRXV6f8/PxIDw2ImIMHD2rbtm0tf9+xY4eqq6vVp08fDRw4MIIjA8KLpYVoUVxcrPnz58vj8Sg1NVWLFi1SZmZmpIcFRMwrr7yis846q1X7pEmT9Mgjj3z/AwI6CMEAAACGY84AAACGIxgAAMBwBAMAABiOYAAAAMMRDAAAYDiCAQAADEcwAACA4QgGAAAwHMEAAACGIxgAAMBwBAMAABiOYAAAAMP9fyl9Gm2oidLQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model training data\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "predictions_xgb = model_xgb.predict(X_test)\n",
    "predictions_xgb = [round(value) for value in predictions_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions_xgb, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0],\n",
       "       [2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, predictions_xgb)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_svm = svm_model.predict(X_test)\n",
    "predictions_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions_svm, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0],\n",
       "       [2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, predictions_svm)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4 (Random Forest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier() #using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rf = RF_model.predict(X_test)\n",
    "predictions_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions_rf, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0],\n",
       "       [2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, predictions_rf)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5 (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(3, activation='relu', input_dim=3))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7612 - binary_accuracy: 0.1579 - val_loss: 0.7423 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7581 - binary_accuracy: 0.1579 - val_loss: 0.7391 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7549 - binary_accuracy: 0.1579 - val_loss: 0.7359 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7518 - binary_accuracy: 0.1579 - val_loss: 0.7327 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7487 - binary_accuracy: 0.1579 - val_loss: 0.7295 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7456 - binary_accuracy: 0.1579 - val_loss: 0.7264 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7426 - binary_accuracy: 0.1579 - val_loss: 0.7233 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7396 - binary_accuracy: 0.1579 - val_loss: 0.7202 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7366 - binary_accuracy: 0.1579 - val_loss: 0.7172 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7336 - binary_accuracy: 0.1579 - val_loss: 0.7142 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7307 - binary_accuracy: 0.1579 - val_loss: 0.7111 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7277 - binary_accuracy: 0.1579 - val_loss: 0.7082 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7248 - binary_accuracy: 0.1579 - val_loss: 0.7052 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7219 - binary_accuracy: 0.1579"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7219 - binary_accuracy: 0.1579 - val_loss: 0.7022 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7191 - binary_accuracy: 0.1579 - val_loss: 0.6993 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7162 - binary_accuracy: 0.1579 - val_loss: 0.6964 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7134 - binary_accuracy: 0.3684 - val_loss: 0.6935 - val_binary_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7106 - binary_accuracy: 0.6316 - val_loss: 0.6907 - val_binary_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7078 - binary_accuracy: 0.6316 - val_loss: 0.6878 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7051 - binary_accuracy: 0.6316 - val_loss: 0.6851 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7025 - binary_accuracy: 0.6316 - val_loss: 0.6824 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6999 - binary_accuracy: 0.6316 - val_loss: 0.6797 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6975 - binary_accuracy: 0.6316 - val_loss: 0.6771 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6950 - binary_accuracy: 0.6316 - val_loss: 0.6745 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6926 - binary_accuracy: 0.6316 - val_loss: 0.6719 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6902 - binary_accuracy: 0.6316 - val_loss: 0.6693 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6878 - binary_accuracy: 0.6316 - val_loss: 0.6667 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6854 - binary_accuracy: 0.6842 - val_loss: 0.6642 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6831 - binary_accuracy: 0.6842 - val_loss: 0.6617 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6807 - binary_accuracy: 0.6842 - val_loss: 0.6592 - val_binary_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6784 - binary_accuracy: 0.6842 - val_loss: 0.6567 - val_binary_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6761 - binary_accuracy: 0.6842 - val_loss: 0.6542 - val_binary_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6738 - binary_accuracy: 0.6842 - val_loss: 0.6517 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6715 - binary_accuracy: 0.6842 - val_loss: 0.6493 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6692 - binary_accuracy: 0.6842 - val_loss: 0.6468 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6670 - binary_accuracy: 0.6842 - val_loss: 0.6444 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6647 - binary_accuracy: 0.6842 - val_loss: 0.6420 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6625 - binary_accuracy: 0.6842 - val_loss: 0.6396 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6603 - binary_accuracy: 0.6842 - val_loss: 0.6373 - val_binary_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6581 - binary_accuracy: 0.6842 - val_loss: 0.6349 - val_binary_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6559 - binary_accuracy: 0.7368 - val_loss: 0.6326 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6537 - binary_accuracy: 0.7368 - val_loss: 0.6303 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6516 - binary_accuracy: 0.7368 - val_loss: 0.6282 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6494 - binary_accuracy: 0.7368 - val_loss: 0.6262 - val_binary_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6473 - binary_accuracy: 0.7368 - val_loss: 0.6242 - val_binary_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6452 - binary_accuracy: 0.7368 - val_loss: 0.6222 - val_binary_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6431 - binary_accuracy: 0.7368 - val_loss: 0.6202 - val_binary_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6410 - binary_accuracy: 0.7368 - val_loss: 0.6182 - val_binary_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6389 - binary_accuracy: 0.7368 - val_loss: 0.6163 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6369 - binary_accuracy: 0.7895 - val_loss: 0.6143 - val_binary_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6348 - binary_accuracy: 0.8421 - val_loss: 0.6124 - val_binary_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6328 - binary_accuracy: 0.8421 - val_loss: 0.6105 - val_binary_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6308 - binary_accuracy: 0.8421 - val_loss: 0.6085 - val_binary_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6288 - binary_accuracy: 0.8421 - val_loss: 0.6066 - val_binary_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6268 - binary_accuracy: 0.8421 - val_loss: 0.6047 - val_binary_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6248 - binary_accuracy: 0.8421 - val_loss: 0.6028 - val_binary_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6228 - binary_accuracy: 0.8421 - val_loss: 0.6010 - val_binary_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6209 - binary_accuracy: 0.8421 - val_loss: 0.5991 - val_binary_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6189 - binary_accuracy: 0.8421 - val_loss: 0.5973 - val_binary_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6171 - binary_accuracy: 0.8421 - val_loss: 0.5954 - val_binary_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6152 - binary_accuracy: 0.8421 - val_loss: 0.5936 - val_binary_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6134 - binary_accuracy: 0.8421 - val_loss: 0.5918 - val_binary_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6115 - binary_accuracy: 0.8421 - val_loss: 0.5899 - val_binary_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6097 - binary_accuracy: 0.8421 - val_loss: 0.5881 - val_binary_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6079 - binary_accuracy: 0.8421 - val_loss: 0.5863 - val_binary_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6061 - binary_accuracy: 0.8421 - val_loss: 0.5846 - val_binary_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6043 - binary_accuracy: 0.8421 - val_loss: 0.5828 - val_binary_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6025 - binary_accuracy: 0.8421 - val_loss: 0.5810 - val_binary_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6008 - binary_accuracy: 0.8421 - val_loss: 0.5793 - val_binary_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5990 - binary_accuracy: 0.8421 - val_loss: 0.5775 - val_binary_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5972 - binary_accuracy: 0.8421 - val_loss: 0.5758 - val_binary_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5955 - binary_accuracy: 0.8421 - val_loss: 0.5740 - val_binary_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5938 - binary_accuracy: 0.8421 - val_loss: 0.5723 - val_binary_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5921 - binary_accuracy: 0.8421 - val_loss: 0.5706 - val_binary_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5904 - binary_accuracy: 0.8421 - val_loss: 0.5689 - val_binary_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5887 - binary_accuracy: 0.8421 - val_loss: 0.5672 - val_binary_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5870 - binary_accuracy: 0.8421 - val_loss: 0.5655 - val_binary_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5853 - binary_accuracy: 0.8421 - val_loss: 0.5639 - val_binary_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5836 - binary_accuracy: 0.8421 - val_loss: 0.5622 - val_binary_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5820 - binary_accuracy: 0.8421 - val_loss: 0.5606 - val_binary_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5803 - binary_accuracy: 0.8421 - val_loss: 0.5589 - val_binary_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5787 - binary_accuracy: 0.8421 - val_loss: 0.5573 - val_binary_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5770 - binary_accuracy: 0.8421 - val_loss: 0.5556 - val_binary_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5754 - binary_accuracy: 0.8421 - val_loss: 0.5540 - val_binary_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5738 - binary_accuracy: 0.8947 - val_loss: 0.5524 - val_binary_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5722 - binary_accuracy: 0.8947 - val_loss: 0.5508 - val_binary_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5706 - binary_accuracy: 0.8947 - val_loss: 0.5492 - val_binary_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5690 - binary_accuracy: 0.8947 - val_loss: 0.5476 - val_binary_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5675 - binary_accuracy: 0.8947 - val_loss: 0.5460 - val_binary_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5659 - binary_accuracy: 0.8947 - val_loss: 0.5445 - val_binary_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5643 - binary_accuracy: 0.8947 - val_loss: 0.5429 - val_binary_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5628 - binary_accuracy: 0.8947 - val_loss: 0.5414 - val_binary_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5612 - binary_accuracy: 0.8947 - val_loss: 0.5398 - val_binary_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5597 - binary_accuracy: 0.8947 - val_loss: 0.5383 - val_binary_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5582 - binary_accuracy: 0.8947 - val_loss: 0.5367 - val_binary_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5567 - binary_accuracy: 0.8947 - val_loss: 0.5352 - val_binary_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5552 - binary_accuracy: 0.8947 - val_loss: 0.5337 - val_binary_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5537 - binary_accuracy: 0.8947 - val_loss: 0.5322 - val_binary_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5522 - binary_accuracy: 0.8947 - val_loss: 0.5307 - val_binary_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5507 - binary_accuracy: 0.8947 - val_loss: 0.5292 - val_binary_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5492 - binary_accuracy: 0.8947 - val_loss: 0.5277 - val_binary_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5477 - binary_accuracy: 0.8947 - val_loss: 0.5262 - val_binary_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5463 - binary_accuracy: 0.8947 - val_loss: 0.5248 - val_binary_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5448 - binary_accuracy: 0.8947 - val_loss: 0.5233 - val_binary_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5434 - binary_accuracy: 0.8947 - val_loss: 0.5219 - val_binary_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5420 - binary_accuracy: 0.8947 - val_loss: 0.5204 - val_binary_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5405 - binary_accuracy: 0.8947 - val_loss: 0.5190 - val_binary_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5391 - binary_accuracy: 0.8947 - val_loss: 0.5175 - val_binary_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5377 - binary_accuracy: 0.8947 - val_loss: 0.5161 - val_binary_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5363 - binary_accuracy: 0.8947 - val_loss: 0.5147 - val_binary_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5349 - binary_accuracy: 0.8947 - val_loss: 0.5133 - val_binary_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5335 - binary_accuracy: 0.8947 - val_loss: 0.5119 - val_binary_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5321 - binary_accuracy: 0.8947 - val_loss: 0.5105 - val_binary_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5308 - binary_accuracy: 0.8947 - val_loss: 0.5091 - val_binary_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5295 - binary_accuracy: 0.8947 - val_loss: 0.5077 - val_binary_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5282 - binary_accuracy: 0.8947 - val_loss: 0.5063 - val_binary_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5269 - binary_accuracy: 0.8947 - val_loss: 0.5049 - val_binary_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5256 - binary_accuracy: 0.8947 - val_loss: 0.5036 - val_binary_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5243 - binary_accuracy: 0.8947 - val_loss: 0.5022 - val_binary_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5230 - binary_accuracy: 0.8947 - val_loss: 0.5009 - val_binary_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5217 - binary_accuracy: 0.8947 - val_loss: 0.4995 - val_binary_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5205 - binary_accuracy: 0.8947 - val_loss: 0.4982 - val_binary_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5192 - binary_accuracy: 0.8947 - val_loss: 0.4969 - val_binary_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5179 - binary_accuracy: 0.8947 - val_loss: 0.4955 - val_binary_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5167 - binary_accuracy: 0.8947 - val_loss: 0.4942 - val_binary_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5155 - binary_accuracy: 0.8947 - val_loss: 0.4929 - val_binary_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5142 - binary_accuracy: 0.8947 - val_loss: 0.4916 - val_binary_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5130 - binary_accuracy: 0.8947 - val_loss: 0.4903 - val_binary_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5118 - binary_accuracy: 0.8947 - val_loss: 0.4890 - val_binary_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5106 - binary_accuracy: 0.8947 - val_loss: 0.4877 - val_binary_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5093 - binary_accuracy: 0.8947 - val_loss: 0.4864 - val_binary_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5081 - binary_accuracy: 0.8947 - val_loss: 0.4852 - val_binary_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5069 - binary_accuracy: 0.8947 - val_loss: 0.4839 - val_binary_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5057 - binary_accuracy: 0.8947 - val_loss: 0.4826 - val_binary_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5046 - binary_accuracy: 0.8947 - val_loss: 0.4814 - val_binary_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5034 - binary_accuracy: 0.8947 - val_loss: 0.4801 - val_binary_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5022 - binary_accuracy: 0.8947 - val_loss: 0.4789 - val_binary_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5010 - binary_accuracy: 0.8947 - val_loss: 0.4776 - val_binary_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4999 - binary_accuracy: 0.8947 - val_loss: 0.4764 - val_binary_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4987 - binary_accuracy: 0.8947 - val_loss: 0.4752 - val_binary_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4975 - binary_accuracy: 0.8947 - val_loss: 0.4739 - val_binary_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4964 - binary_accuracy: 0.8947 - val_loss: 0.4727 - val_binary_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4952 - binary_accuracy: 0.8947 - val_loss: 0.4715 - val_binary_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4941 - binary_accuracy: 0.8947 - val_loss: 0.4703 - val_binary_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4930 - binary_accuracy: 0.8947 - val_loss: 0.4691 - val_binary_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4918 - binary_accuracy: 0.8947 - val_loss: 0.4679 - val_binary_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4907 - binary_accuracy: 0.8947 - val_loss: 0.4667 - val_binary_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4896 - binary_accuracy: 0.8947 - val_loss: 0.4655 - val_binary_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4885 - binary_accuracy: 0.8947 - val_loss: 0.4643 - val_binary_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4874 - binary_accuracy: 0.8947 - val_loss: 0.4632 - val_binary_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4863 - binary_accuracy: 0.8947 - val_loss: 0.4620 - val_binary_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4852 - binary_accuracy: 0.8947 - val_loss: 0.4608 - val_binary_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4841 - binary_accuracy: 0.8947 - val_loss: 0.4597 - val_binary_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4830 - binary_accuracy: 0.8947 - val_loss: 0.4585 - val_binary_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4819 - binary_accuracy: 0.8947 - val_loss: 0.4574 - val_binary_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4808 - binary_accuracy: 0.8947 - val_loss: 0.4562 - val_binary_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4798 - binary_accuracy: 0.8947 - val_loss: 0.4551 - val_binary_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4787 - binary_accuracy: 0.8947 - val_loss: 0.4539 - val_binary_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4776 - binary_accuracy: 0.8947 - val_loss: 0.4528 - val_binary_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4766 - binary_accuracy: 0.8947 - val_loss: 0.4517 - val_binary_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4755 - binary_accuracy: 0.8947 - val_loss: 0.4506 - val_binary_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4745 - binary_accuracy: 0.8947 - val_loss: 0.4495 - val_binary_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4734 - binary_accuracy: 0.8947 - val_loss: 0.4483 - val_binary_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4724 - binary_accuracy: 0.8947 - val_loss: 0.4472 - val_binary_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4714 - binary_accuracy: 0.8947 - val_loss: 0.4461 - val_binary_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4703 - binary_accuracy: 0.8947 - val_loss: 0.4451 - val_binary_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4693 - binary_accuracy: 0.8947 - val_loss: 0.4440 - val_binary_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4683 - binary_accuracy: 0.8947 - val_loss: 0.4429 - val_binary_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4673 - binary_accuracy: 0.8947 - val_loss: 0.4418 - val_binary_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4663 - binary_accuracy: 0.8947 - val_loss: 0.4407 - val_binary_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4652 - binary_accuracy: 0.8947 - val_loss: 0.4396 - val_binary_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4642 - binary_accuracy: 0.8947 - val_loss: 0.4386 - val_binary_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4632 - binary_accuracy: 0.8947 - val_loss: 0.4375 - val_binary_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4622 - binary_accuracy: 0.8947 - val_loss: 0.4365 - val_binary_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4613 - binary_accuracy: 0.8947 - val_loss: 0.4354 - val_binary_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4603 - binary_accuracy: 0.8947 - val_loss: 0.4344 - val_binary_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4593 - binary_accuracy: 0.8947 - val_loss: 0.4333 - val_binary_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4583 - binary_accuracy: 0.8947 - val_loss: 0.4323 - val_binary_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4573 - binary_accuracy: 0.8947 - val_loss: 0.4312 - val_binary_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4564 - binary_accuracy: 0.8947 - val_loss: 0.4302 - val_binary_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4554 - binary_accuracy: 0.8947 - val_loss: 0.4292 - val_binary_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4544 - binary_accuracy: 0.8947 - val_loss: 0.4282 - val_binary_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4535 - binary_accuracy: 0.8947 - val_loss: 0.4271 - val_binary_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4525 - binary_accuracy: 0.8947 - val_loss: 0.4261 - val_binary_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4516 - binary_accuracy: 0.8947 - val_loss: 0.4251 - val_binary_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4506 - binary_accuracy: 0.8947 - val_loss: 0.4241 - val_binary_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4497 - binary_accuracy: 0.8947 - val_loss: 0.4231 - val_binary_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4488 - binary_accuracy: 0.8947 - val_loss: 0.4221 - val_binary_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4478 - binary_accuracy: 0.8947 - val_loss: 0.4211 - val_binary_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4469 - binary_accuracy: 0.8947 - val_loss: 0.4201 - val_binary_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4460 - binary_accuracy: 0.8947 - val_loss: 0.4192 - val_binary_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4450 - binary_accuracy: 0.8947 - val_loss: 0.4182 - val_binary_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4441 - binary_accuracy: 0.8947 - val_loss: 0.4172 - val_binary_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4432 - binary_accuracy: 0.8947 - val_loss: 0.4162 - val_binary_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4423 - binary_accuracy: 0.8947 - val_loss: 0.4153 - val_binary_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4414 - binary_accuracy: 0.8947 - val_loss: 0.4143 - val_binary_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4405 - binary_accuracy: 0.8947 - val_loss: 0.4133 - val_binary_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4396 - binary_accuracy: 0.8947 - val_loss: 0.4124 - val_binary_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4387 - binary_accuracy: 0.8947 - val_loss: 0.4114 - val_binary_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4378 - binary_accuracy: 0.8947 - val_loss: 0.4105 - val_binary_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4369 - binary_accuracy: 0.8947 - val_loss: 0.4095 - val_binary_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4360 - binary_accuracy: 0.8947 - val_loss: 0.4086 - val_binary_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4351 - binary_accuracy: 0.8947 - val_loss: 0.4077 - val_binary_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4343 - binary_accuracy: 0.8947 - val_loss: 0.4067 - val_binary_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4334 - binary_accuracy: 0.8947 - val_loss: 0.4058 - val_binary_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4325 - binary_accuracy: 0.8947 - val_loss: 0.4049 - val_binary_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4316 - binary_accuracy: 0.8947 - val_loss: 0.4040 - val_binary_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4308 - binary_accuracy: 0.8947 - val_loss: 0.4030 - val_binary_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4299 - binary_accuracy: 0.8947 - val_loss: 0.4021 - val_binary_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4291 - binary_accuracy: 0.8947 - val_loss: 0.4012 - val_binary_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4282 - binary_accuracy: 0.8947 - val_loss: 0.4003 - val_binary_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4274 - binary_accuracy: 0.8947 - val_loss: 0.3994 - val_binary_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4265 - binary_accuracy: 1.0000 - val_loss: 0.3985 - val_binary_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4257 - binary_accuracy: 1.0000 - val_loss: 0.3976 - val_binary_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4248 - binary_accuracy: 1.0000 - val_loss: 0.3967 - val_binary_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4240 - binary_accuracy: 1.0000 - val_loss: 0.3958 - val_binary_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4232 - binary_accuracy: 1.0000 - val_loss: 0.3949 - val_binary_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4224 - binary_accuracy: 1.0000 - val_loss: 0.3941 - val_binary_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4216 - binary_accuracy: 1.0000 - val_loss: 0.3932 - val_binary_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4208 - binary_accuracy: 1.0000 - val_loss: 0.3923 - val_binary_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4200 - binary_accuracy: 1.0000 - val_loss: 0.3914 - val_binary_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4193 - binary_accuracy: 1.0000 - val_loss: 0.3906 - val_binary_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4185 - binary_accuracy: 1.0000 - val_loss: 0.3897 - val_binary_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4177 - binary_accuracy: 1.0000 - val_loss: 0.3888 - val_binary_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4169 - binary_accuracy: 1.0000 - val_loss: 0.3880 - val_binary_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4162 - binary_accuracy: 1.0000 - val_loss: 0.3871 - val_binary_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4154 - binary_accuracy: 1.0000 - val_loss: 0.3863 - val_binary_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4147 - binary_accuracy: 1.0000 - val_loss: 0.3854 - val_binary_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4139 - binary_accuracy: 1.0000 - val_loss: 0.3846 - val_binary_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4131 - binary_accuracy: 1.0000 - val_loss: 0.3837 - val_binary_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4124 - binary_accuracy: 1.0000 - val_loss: 0.3829 - val_binary_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4116 - binary_accuracy: 1.0000 - val_loss: 0.3821 - val_binary_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4109 - binary_accuracy: 1.0000 - val_loss: 0.3812 - val_binary_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4101 - binary_accuracy: 1.0000 - val_loss: 0.3804 - val_binary_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4094 - binary_accuracy: 1.0000 - val_loss: 0.3796 - val_binary_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4086 - binary_accuracy: 1.0000 - val_loss: 0.3787 - val_binary_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4079 - binary_accuracy: 1.0000 - val_loss: 0.3779 - val_binary_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4072 - binary_accuracy: 1.0000 - val_loss: 0.3771 - val_binary_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4064 - binary_accuracy: 1.0000 - val_loss: 0.3763 - val_binary_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4057 - binary_accuracy: 1.0000 - val_loss: 0.3755 - val_binary_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4050 - binary_accuracy: 1.0000 - val_loss: 0.3747 - val_binary_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4042 - binary_accuracy: 1.0000 - val_loss: 0.3739 - val_binary_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4035 - binary_accuracy: 1.0000 - val_loss: 0.3731 - val_binary_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4028 - binary_accuracy: 1.0000 - val_loss: 0.3723 - val_binary_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4021 - binary_accuracy: 1.0000 - val_loss: 0.3715 - val_binary_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4013 - binary_accuracy: 1.0000 - val_loss: 0.3707 - val_binary_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4006 - binary_accuracy: 1.0000 - val_loss: 0.3699 - val_binary_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3999 - binary_accuracy: 1.0000 - val_loss: 0.3691 - val_binary_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3992 - binary_accuracy: 1.0000 - val_loss: 0.3683 - val_binary_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3985 - binary_accuracy: 1.0000 - val_loss: 0.3675 - val_binary_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3978 - binary_accuracy: 1.0000 - val_loss: 0.3668 - val_binary_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3971 - binary_accuracy: 1.0000 - val_loss: 0.3660 - val_binary_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3964 - binary_accuracy: 1.0000 - val_loss: 0.3652 - val_binary_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3957 - binary_accuracy: 1.0000 - val_loss: 0.3644 - val_binary_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3950 - binary_accuracy: 1.0000 - val_loss: 0.3637 - val_binary_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3943 - binary_accuracy: 1.0000 - val_loss: 0.3629 - val_binary_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3936 - binary_accuracy: 1.0000 - val_loss: 0.3621 - val_binary_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3929 - binary_accuracy: 1.0000 - val_loss: 0.3614 - val_binary_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3922 - binary_accuracy: 1.0000 - val_loss: 0.3606 - val_binary_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3915 - binary_accuracy: 1.0000 - val_loss: 0.3599 - val_binary_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3908 - binary_accuracy: 1.0000 - val_loss: 0.3591 - val_binary_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3902 - binary_accuracy: 1.0000 - val_loss: 0.3584 - val_binary_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3895 - binary_accuracy: 1.0000 - val_loss: 0.3576 - val_binary_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3888 - binary_accuracy: 1.0000 - val_loss: 0.3569 - val_binary_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3881 - binary_accuracy: 1.0000 - val_loss: 0.3561 - val_binary_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3874 - binary_accuracy: 1.0000 - val_loss: 0.3554 - val_binary_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3868 - binary_accuracy: 1.0000 - val_loss: 0.3547 - val_binary_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3861 - binary_accuracy: 1.0000 - val_loss: 0.3539 - val_binary_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3854 - binary_accuracy: 1.0000 - val_loss: 0.3532 - val_binary_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3848 - binary_accuracy: 1.0000 - val_loss: 0.3525 - val_binary_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3841 - binary_accuracy: 1.0000 - val_loss: 0.3517 - val_binary_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3834 - binary_accuracy: 1.0000 - val_loss: 0.3510 - val_binary_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3828 - binary_accuracy: 1.0000 - val_loss: 0.3503 - val_binary_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3821 - binary_accuracy: 1.0000 - val_loss: 0.3496 - val_binary_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3815 - binary_accuracy: 1.0000 - val_loss: 0.3489 - val_binary_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3808 - binary_accuracy: 1.0000 - val_loss: 0.3481 - val_binary_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3802 - binary_accuracy: 1.0000 - val_loss: 0.3474 - val_binary_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3795 - binary_accuracy: 1.0000 - val_loss: 0.3467 - val_binary_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3789 - binary_accuracy: 1.0000 - val_loss: 0.3460 - val_binary_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3782 - binary_accuracy: 1.0000 - val_loss: 0.3453 - val_binary_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3776 - binary_accuracy: 1.0000 - val_loss: 0.3446 - val_binary_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3769 - binary_accuracy: 1.0000 - val_loss: 0.3439 - val_binary_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3763 - binary_accuracy: 1.0000 - val_loss: 0.3432 - val_binary_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3757 - binary_accuracy: 1.0000 - val_loss: 0.3425 - val_binary_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3750 - binary_accuracy: 1.0000 - val_loss: 0.3418 - val_binary_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3744 - binary_accuracy: 1.0000 - val_loss: 0.3411 - val_binary_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3738 - binary_accuracy: 1.0000 - val_loss: 0.3404 - val_binary_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3731 - binary_accuracy: 1.0000 - val_loss: 0.3398 - val_binary_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3725 - binary_accuracy: 1.0000 - val_loss: 0.3391 - val_binary_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3719 - binary_accuracy: 1.0000 - val_loss: 0.3384 - val_binary_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3713 - binary_accuracy: 1.0000 - val_loss: 0.3377 - val_binary_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3706 - binary_accuracy: 1.0000 - val_loss: 0.3370 - val_binary_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3700 - binary_accuracy: 1.0000 - val_loss: 0.3364 - val_binary_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3694 - binary_accuracy: 1.0000 - val_loss: 0.3357 - val_binary_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3688 - binary_accuracy: 1.0000 - val_loss: 0.3350 - val_binary_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3682 - binary_accuracy: 1.0000 - val_loss: 0.3344 - val_binary_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3675 - binary_accuracy: 1.0000 - val_loss: 0.3337 - val_binary_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3669 - binary_accuracy: 1.0000 - val_loss: 0.3330 - val_binary_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3663 - binary_accuracy: 1.0000 - val_loss: 0.3324 - val_binary_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3657 - binary_accuracy: 1.0000 - val_loss: 0.3317 - val_binary_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3651 - binary_accuracy: 1.0000 - val_loss: 0.3311 - val_binary_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3645 - binary_accuracy: 1.0000 - val_loss: 0.3304 - val_binary_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3639 - binary_accuracy: 1.0000 - val_loss: 0.3298 - val_binary_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3633 - binary_accuracy: 1.0000 - val_loss: 0.3291 - val_binary_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3627 - binary_accuracy: 1.0000 - val_loss: 0.3285 - val_binary_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3621 - binary_accuracy: 1.0000 - val_loss: 0.3278 - val_binary_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3615 - binary_accuracy: 1.0000 - val_loss: 0.3272 - val_binary_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3609 - binary_accuracy: 1.0000 - val_loss: 0.3265 - val_binary_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3603 - binary_accuracy: 1.0000 - val_loss: 0.3259 - val_binary_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3597 - binary_accuracy: 1.0000 - val_loss: 0.3252 - val_binary_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3591 - binary_accuracy: 1.0000 - val_loss: 0.3246 - val_binary_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3585 - binary_accuracy: 1.0000 - val_loss: 0.3240 - val_binary_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3579 - binary_accuracy: 1.0000 - val_loss: 0.3233 - val_binary_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3574 - binary_accuracy: 1.0000 - val_loss: 0.3227 - val_binary_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3568 - binary_accuracy: 1.0000 - val_loss: 0.3221 - val_binary_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3562 - binary_accuracy: 1.0000 - val_loss: 0.3215 - val_binary_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3556 - binary_accuracy: 1.0000 - val_loss: 0.3208 - val_binary_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3550 - binary_accuracy: 1.0000 - val_loss: 0.3202 - val_binary_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3544 - binary_accuracy: 1.0000 - val_loss: 0.3196 - val_binary_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3539 - binary_accuracy: 1.0000 - val_loss: 0.3190 - val_binary_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3533 - binary_accuracy: 1.0000 - val_loss: 0.3184 - val_binary_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3527 - binary_accuracy: 1.0000 - val_loss: 0.3178 - val_binary_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3522 - binary_accuracy: 1.0000 - val_loss: 0.3171 - val_binary_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3516 - binary_accuracy: 1.0000 - val_loss: 0.3165 - val_binary_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3510 - binary_accuracy: 1.0000 - val_loss: 0.3159 - val_binary_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3504 - binary_accuracy: 1.0000 - val_loss: 0.3153 - val_binary_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3499 - binary_accuracy: 1.0000 - val_loss: 0.3147 - val_binary_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3493 - binary_accuracy: 1.0000 - val_loss: 0.3141 - val_binary_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3488 - binary_accuracy: 1.0000 - val_loss: 0.3135 - val_binary_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3482 - binary_accuracy: 1.0000 - val_loss: 0.3129 - val_binary_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3476 - binary_accuracy: 1.0000 - val_loss: 0.3123 - val_binary_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3471 - binary_accuracy: 1.0000 - val_loss: 0.3117 - val_binary_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3465 - binary_accuracy: 1.0000 - val_loss: 0.3111 - val_binary_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3460 - binary_accuracy: 1.0000 - val_loss: 0.3105 - val_binary_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3454 - binary_accuracy: 1.0000 - val_loss: 0.3100 - val_binary_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3449 - binary_accuracy: 1.0000 - val_loss: 0.3094 - val_binary_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3443 - binary_accuracy: 1.0000 - val_loss: 0.3088 - val_binary_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3438 - binary_accuracy: 1.0000 - val_loss: 0.3082 - val_binary_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3432 - binary_accuracy: 1.0000 - val_loss: 0.3076 - val_binary_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3427 - binary_accuracy: 1.0000 - val_loss: 0.3070 - val_binary_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3421 - binary_accuracy: 1.0000 - val_loss: 0.3065 - val_binary_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3416 - binary_accuracy: 1.0000 - val_loss: 0.3059 - val_binary_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3410 - binary_accuracy: 1.0000 - val_loss: 0.3053 - val_binary_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3405 - binary_accuracy: 1.0000 - val_loss: 0.3047 - val_binary_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3400 - binary_accuracy: 1.0000 - val_loss: 0.3042 - val_binary_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3394 - binary_accuracy: 1.0000 - val_loss: 0.3036 - val_binary_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3389 - binary_accuracy: 1.0000 - val_loss: 0.3030 - val_binary_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3383 - binary_accuracy: 1.0000 - val_loss: 0.3025 - val_binary_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3378 - binary_accuracy: 1.0000 - val_loss: 0.3019 - val_binary_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3373 - binary_accuracy: 1.0000 - val_loss: 0.3013 - val_binary_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3367 - binary_accuracy: 1.0000 - val_loss: 0.3008 - val_binary_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3362 - binary_accuracy: 1.0000 - val_loss: 0.3002 - val_binary_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3357 - binary_accuracy: 1.0000 - val_loss: 0.2996 - val_binary_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3352 - binary_accuracy: 1.0000 - val_loss: 0.2991 - val_binary_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3346 - binary_accuracy: 1.0000 - val_loss: 0.2985 - val_binary_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3341 - binary_accuracy: 1.0000 - val_loss: 0.2980 - val_binary_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3336 - binary_accuracy: 1.0000 - val_loss: 0.2974 - val_binary_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3331 - binary_accuracy: 1.0000 - val_loss: 0.2969 - val_binary_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3325 - binary_accuracy: 1.0000 - val_loss: 0.2963 - val_binary_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3320 - binary_accuracy: 1.0000 - val_loss: 0.2958 - val_binary_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3315 - binary_accuracy: 1.0000 - val_loss: 0.2952 - val_binary_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3310 - binary_accuracy: 1.0000 - val_loss: 0.2947 - val_binary_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3305 - binary_accuracy: 1.0000 - val_loss: 0.2942 - val_binary_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3300 - binary_accuracy: 1.0000 - val_loss: 0.2936 - val_binary_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3294 - binary_accuracy: 1.0000 - val_loss: 0.2931 - val_binary_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3289 - binary_accuracy: 1.0000 - val_loss: 0.2925 - val_binary_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3284 - binary_accuracy: 1.0000 - val_loss: 0.2920 - val_binary_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3279 - binary_accuracy: 1.0000 - val_loss: 0.2915 - val_binary_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3274 - binary_accuracy: 1.0000 - val_loss: 0.2909 - val_binary_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3269 - binary_accuracy: 1.0000 - val_loss: 0.2904 - val_binary_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3264 - binary_accuracy: 1.0000 - val_loss: 0.2899 - val_binary_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3259 - binary_accuracy: 1.0000 - val_loss: 0.2893 - val_binary_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3254 - binary_accuracy: 1.0000 - val_loss: 0.2888 - val_binary_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3249 - binary_accuracy: 1.0000 - val_loss: 0.2883 - val_binary_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3244 - binary_accuracy: 1.0000 - val_loss: 0.2878 - val_binary_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3239 - binary_accuracy: 1.0000 - val_loss: 0.2873 - val_binary_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3234 - binary_accuracy: 1.0000 - val_loss: 0.2867 - val_binary_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3229 - binary_accuracy: 1.0000 - val_loss: 0.2862 - val_binary_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3224 - binary_accuracy: 1.0000 - val_loss: 0.2857 - val_binary_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3219 - binary_accuracy: 1.0000 - val_loss: 0.2852 - val_binary_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3214 - binary_accuracy: 1.0000 - val_loss: 0.2847 - val_binary_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3209 - binary_accuracy: 1.0000 - val_loss: 0.2842 - val_binary_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3204 - binary_accuracy: 1.0000 - val_loss: 0.2836 - val_binary_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3199 - binary_accuracy: 1.0000 - val_loss: 0.2831 - val_binary_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3195 - binary_accuracy: 1.0000 - val_loss: 0.2826 - val_binary_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3190 - binary_accuracy: 1.0000 - val_loss: 0.2821 - val_binary_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3185 - binary_accuracy: 1.0000 - val_loss: 0.2816 - val_binary_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3180 - binary_accuracy: 1.0000 - val_loss: 0.2811 - val_binary_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3175 - binary_accuracy: 1.0000 - val_loss: 0.2806 - val_binary_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3170 - binary_accuracy: 1.0000 - val_loss: 0.2801 - val_binary_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3165 - binary_accuracy: 1.0000 - val_loss: 0.2796 - val_binary_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3161 - binary_accuracy: 1.0000 - val_loss: 0.2791 - val_binary_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3156 - binary_accuracy: 1.0000 - val_loss: 0.2786 - val_binary_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3151 - binary_accuracy: 1.0000 - val_loss: 0.2781 - val_binary_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3146 - binary_accuracy: 1.0000 - val_loss: 0.2776 - val_binary_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3142 - binary_accuracy: 1.0000 - val_loss: 0.2771 - val_binary_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3137 - binary_accuracy: 1.0000 - val_loss: 0.2766 - val_binary_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3132 - binary_accuracy: 1.0000 - val_loss: 0.2761 - val_binary_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3127 - binary_accuracy: 1.0000 - val_loss: 0.2756 - val_binary_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3123 - binary_accuracy: 1.0000 - val_loss: 0.2752 - val_binary_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3118 - binary_accuracy: 1.0000 - val_loss: 0.2747 - val_binary_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3113 - binary_accuracy: 1.0000 - val_loss: 0.2742 - val_binary_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3109 - binary_accuracy: 1.0000 - val_loss: 0.2737 - val_binary_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3104 - binary_accuracy: 1.0000 - val_loss: 0.2732 - val_binary_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3099 - binary_accuracy: 1.0000 - val_loss: 0.2727 - val_binary_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3095 - binary_accuracy: 1.0000 - val_loss: 0.2723 - val_binary_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3090 - binary_accuracy: 1.0000 - val_loss: 0.2718 - val_binary_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3085 - binary_accuracy: 1.0000 - val_loss: 0.2713 - val_binary_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3081 - binary_accuracy: 1.0000 - val_loss: 0.2708 - val_binary_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3076 - binary_accuracy: 1.0000 - val_loss: 0.2704 - val_binary_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3072 - binary_accuracy: 1.0000 - val_loss: 0.2699 - val_binary_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3067 - binary_accuracy: 1.0000 - val_loss: 0.2694 - val_binary_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3062 - binary_accuracy: 1.0000 - val_loss: 0.2689 - val_binary_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3058 - binary_accuracy: 1.0000 - val_loss: 0.2685 - val_binary_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3053 - binary_accuracy: 1.0000 - val_loss: 0.2680 - val_binary_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3049 - binary_accuracy: 1.0000 - val_loss: 0.2675 - val_binary_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3044 - binary_accuracy: 1.0000 - val_loss: 0.2671 - val_binary_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3040 - binary_accuracy: 1.0000 - val_loss: 0.2666 - val_binary_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3035 - binary_accuracy: 1.0000 - val_loss: 0.2661 - val_binary_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3031 - binary_accuracy: 1.0000 - val_loss: 0.2657 - val_binary_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3026 - binary_accuracy: 1.0000 - val_loss: 0.2652 - val_binary_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3022 - binary_accuracy: 1.0000 - val_loss: 0.2648 - val_binary_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3017 - binary_accuracy: 1.0000 - val_loss: 0.2643 - val_binary_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3013 - binary_accuracy: 1.0000 - val_loss: 0.2638 - val_binary_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3008 - binary_accuracy: 1.0000 - val_loss: 0.2634 - val_binary_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3004 - binary_accuracy: 1.0000 - val_loss: 0.2629 - val_binary_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3000 - binary_accuracy: 1.0000 - val_loss: 0.2625 - val_binary_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2995 - binary_accuracy: 1.0000 - val_loss: 0.2620 - val_binary_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2991 - binary_accuracy: 1.0000 - val_loss: 0.2616 - val_binary_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2987 - binary_accuracy: 1.0000 - val_loss: 0.2611 - val_binary_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2982 - binary_accuracy: 1.0000 - val_loss: 0.2607 - val_binary_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2978 - binary_accuracy: 1.0000 - val_loss: 0.2602 - val_binary_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2974 - binary_accuracy: 1.0000 - val_loss: 0.2598 - val_binary_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2969 - binary_accuracy: 1.0000 - val_loss: 0.2593 - val_binary_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2965 - binary_accuracy: 1.0000 - val_loss: 0.2589 - val_binary_accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2961 - binary_accuracy: 1.0000 - val_loss: 0.2584 - val_binary_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2956 - binary_accuracy: 1.0000 - val_loss: 0.2580 - val_binary_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2952 - binary_accuracy: 1.0000 - val_loss: 0.2576 - val_binary_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2948 - binary_accuracy: 1.0000 - val_loss: 0.2571 - val_binary_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2944 - binary_accuracy: 1.0000 - val_loss: 0.2567 - val_binary_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2939 - binary_accuracy: 1.0000 - val_loss: 0.2562 - val_binary_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2935 - binary_accuracy: 1.0000 - val_loss: 0.2558 - val_binary_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2931 - binary_accuracy: 1.0000 - val_loss: 0.2554 - val_binary_accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2927 - binary_accuracy: 1.0000 - val_loss: 0.2549 - val_binary_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2922 - binary_accuracy: 1.0000 - val_loss: 0.2545 - val_binary_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2918 - binary_accuracy: 1.0000 - val_loss: 0.2541 - val_binary_accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2914 - binary_accuracy: 1.0000 - val_loss: 0.2536 - val_binary_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2910 - binary_accuracy: 1.0000 - val_loss: 0.2532 - val_binary_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2906 - binary_accuracy: 1.0000 - val_loss: 0.2528 - val_binary_accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2901 - binary_accuracy: 1.0000 - val_loss: 0.2523 - val_binary_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2897 - binary_accuracy: 1.0000 - val_loss: 0.2519 - val_binary_accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2893 - binary_accuracy: 1.0000 - val_loss: 0.2515 - val_binary_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2889 - binary_accuracy: 1.0000 - val_loss: 0.2511 - val_binary_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2885 - binary_accuracy: 1.0000 - val_loss: 0.2506 - val_binary_accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2881 - binary_accuracy: 1.0000 - val_loss: 0.2502 - val_binary_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2877 - binary_accuracy: 1.0000 - val_loss: 0.2498 - val_binary_accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2873 - binary_accuracy: 1.0000 - val_loss: 0.2494 - val_binary_accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2869 - binary_accuracy: 1.0000 - val_loss: 0.2490 - val_binary_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2864 - binary_accuracy: 1.0000 - val_loss: 0.2485 - val_binary_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2860 - binary_accuracy: 1.0000 - val_loss: 0.2481 - val_binary_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2856 - binary_accuracy: 1.0000 - val_loss: 0.2477 - val_binary_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2852 - binary_accuracy: 1.0000 - val_loss: 0.2473 - val_binary_accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2848 - binary_accuracy: 1.0000 - val_loss: 0.2469 - val_binary_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2844 - binary_accuracy: 1.0000 - val_loss: 0.2465 - val_binary_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2840 - binary_accuracy: 1.0000 - val_loss: 0.2461 - val_binary_accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2836 - binary_accuracy: 1.0000 - val_loss: 0.2456 - val_binary_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2832 - binary_accuracy: 1.0000 - val_loss: 0.2452 - val_binary_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2828 - binary_accuracy: 1.0000 - val_loss: 0.2448 - val_binary_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2824 - binary_accuracy: 1.0000 - val_loss: 0.2444 - val_binary_accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2820 - binary_accuracy: 1.0000 - val_loss: 0.2440 - val_binary_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2816 - binary_accuracy: 1.0000 - val_loss: 0.2436 - val_binary_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2812 - binary_accuracy: 1.0000 - val_loss: 0.2432 - val_binary_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2808 - binary_accuracy: 1.0000 - val_loss: 0.2428 - val_binary_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2804 - binary_accuracy: 1.0000 - val_loss: 0.2424 - val_binary_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2800 - binary_accuracy: 1.0000 - val_loss: 0.2420 - val_binary_accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2796 - binary_accuracy: 1.0000 - val_loss: 0.2416 - val_binary_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2792 - binary_accuracy: 1.0000 - val_loss: 0.2412 - val_binary_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2789 - binary_accuracy: 1.0000 - val_loss: 0.2408 - val_binary_accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2785 - binary_accuracy: 1.0000 - val_loss: 0.2404 - val_binary_accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2781 - binary_accuracy: 1.0000 - val_loss: 0.2400 - val_binary_accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2777 - binary_accuracy: 1.0000 - val_loss: 0.2396 - val_binary_accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2773 - binary_accuracy: 1.0000 - val_loss: 0.2392 - val_binary_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2769 - binary_accuracy: 1.0000 - val_loss: 0.2388 - val_binary_accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2765 - binary_accuracy: 1.0000 - val_loss: 0.2384 - val_binary_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2761 - binary_accuracy: 1.0000 - val_loss: 0.2380 - val_binary_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2757 - binary_accuracy: 1.0000 - val_loss: 0.2376 - val_binary_accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2754 - binary_accuracy: 1.0000 - val_loss: 0.2372 - val_binary_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2750 - binary_accuracy: 1.0000 - val_loss: 0.2369 - val_binary_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2746 - binary_accuracy: 1.0000 - val_loss: 0.2365 - val_binary_accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2742 - binary_accuracy: 1.0000 - val_loss: 0.2361 - val_binary_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2738 - binary_accuracy: 1.0000 - val_loss: 0.2357 - val_binary_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2735 - binary_accuracy: 1.0000 - val_loss: 0.2353 - val_binary_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2731 - binary_accuracy: 1.0000 - val_loss: 0.2349 - val_binary_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2727 - binary_accuracy: 1.0000 - val_loss: 0.2345 - val_binary_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2723 - binary_accuracy: 1.0000 - val_loss: 0.2342 - val_binary_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2719 - binary_accuracy: 1.0000 - val_loss: 0.2338 - val_binary_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2716 - binary_accuracy: 1.0000 - val_loss: 0.2334 - val_binary_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2712 - binary_accuracy: 1.0000 - val_loss: 0.2330 - val_binary_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2708 - binary_accuracy: 1.0000 - val_loss: 0.2326 - val_binary_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2704 - binary_accuracy: 1.0000 - val_loss: 0.2323 - val_binary_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2701 - binary_accuracy: 1.0000 - val_loss: 0.2319 - val_binary_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2697 - binary_accuracy: 1.0000 - val_loss: 0.2315 - val_binary_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2693 - binary_accuracy: 1.0000 - val_loss: 0.2311 - val_binary_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2690 - binary_accuracy: 1.0000 - val_loss: 0.2308 - val_binary_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2686 - binary_accuracy: 1.0000 - val_loss: 0.2304 - val_binary_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2682 - binary_accuracy: 1.0000 - val_loss: 0.2300 - val_binary_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2678 - binary_accuracy: 1.0000 - val_loss: 0.2296 - val_binary_accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2675 - binary_accuracy: 1.0000 - val_loss: 0.2293 - val_binary_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2671 - binary_accuracy: 1.0000 - val_loss: 0.2289 - val_binary_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2667 - binary_accuracy: 1.0000 - val_loss: 0.2285 - val_binary_accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2664 - binary_accuracy: 1.0000 - val_loss: 0.2282 - val_binary_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2660 - binary_accuracy: 1.0000 - val_loss: 0.2278 - val_binary_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2656 - binary_accuracy: 1.0000 - val_loss: 0.2274 - val_binary_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2653 - binary_accuracy: 1.0000 - val_loss: 0.2271 - val_binary_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2649 - binary_accuracy: 1.0000 - val_loss: 0.2267 - val_binary_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2646 - binary_accuracy: 1.0000 - val_loss: 0.2263 - val_binary_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2642 - binary_accuracy: 1.0000 - val_loss: 0.2260 - val_binary_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2638 - binary_accuracy: 1.0000 - val_loss: 0.2256 - val_binary_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2635 - binary_accuracy: 1.0000 - val_loss: 0.2252 - val_binary_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2631 - binary_accuracy: 1.0000 - val_loss: 0.2249 - val_binary_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2628 - binary_accuracy: 1.0000 - val_loss: 0.2245 - val_binary_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2624 - binary_accuracy: 1.0000 - val_loss: 0.2242 - val_binary_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2620 - binary_accuracy: 1.0000 - val_loss: 0.2238 - val_binary_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2617 - binary_accuracy: 1.0000 - val_loss: 0.2234 - val_binary_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2613 - binary_accuracy: 1.0000 - val_loss: 0.2231 - val_binary_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2610 - binary_accuracy: 1.0000 - val_loss: 0.2227 - val_binary_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2606 - binary_accuracy: 1.0000 - val_loss: 0.2224 - val_binary_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2603 - binary_accuracy: 1.0000 - val_loss: 0.2220 - val_binary_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2599 - binary_accuracy: 1.0000 - val_loss: 0.2217 - val_binary_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2596 - binary_accuracy: 1.0000 - val_loss: 0.2213 - val_binary_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2592 - binary_accuracy: 1.0000 - val_loss: 0.2210 - val_binary_accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2589 - binary_accuracy: 1.0000 - val_loss: 0.2206 - val_binary_accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2585 - binary_accuracy: 1.0000 - val_loss: 0.2202 - val_binary_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2582 - binary_accuracy: 1.0000 - val_loss: 0.2199 - val_binary_accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2578 - binary_accuracy: 1.0000 - val_loss: 0.2196 - val_binary_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2575 - binary_accuracy: 1.0000 - val_loss: 0.2192 - val_binary_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2571 - binary_accuracy: 1.0000 - val_loss: 0.2189 - val_binary_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2568 - binary_accuracy: 1.0000 - val_loss: 0.2185 - val_binary_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2564 - binary_accuracy: 1.0000 - val_loss: 0.2182 - val_binary_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2561 - binary_accuracy: 1.0000 - val_loss: 0.2178 - val_binary_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2557 - binary_accuracy: 1.0000 - val_loss: 0.2175 - val_binary_accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2554 - binary_accuracy: 1.0000 - val_loss: 0.2171 - val_binary_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2551 - binary_accuracy: 1.0000 - val_loss: 0.2168 - val_binary_accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2547 - binary_accuracy: 1.0000 - val_loss: 0.2164 - val_binary_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2544 - binary_accuracy: 1.0000 - val_loss: 0.2161 - val_binary_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2540 - binary_accuracy: 1.0000 - val_loss: 0.2158 - val_binary_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2537 - binary_accuracy: 1.0000 - val_loss: 0.2154 - val_binary_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2534 - binary_accuracy: 1.0000 - val_loss: 0.2151 - val_binary_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2530 - binary_accuracy: 1.0000 - val_loss: 0.2147 - val_binary_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2527 - binary_accuracy: 1.0000 - val_loss: 0.2144 - val_binary_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2523 - binary_accuracy: 1.0000 - val_loss: 0.2141 - val_binary_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2520 - binary_accuracy: 1.0000 - val_loss: 0.2137 - val_binary_accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2517 - binary_accuracy: 1.0000 - val_loss: 0.2134 - val_binary_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2513 - binary_accuracy: 1.0000 - val_loss: 0.2131 - val_binary_accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2510 - binary_accuracy: 1.0000 - val_loss: 0.2127 - val_binary_accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2507 - binary_accuracy: 1.0000 - val_loss: 0.2124 - val_binary_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2503 - binary_accuracy: 1.0000 - val_loss: 0.2121 - val_binary_accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2500 - binary_accuracy: 1.0000 - val_loss: 0.2117 - val_binary_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2497 - binary_accuracy: 1.0000 - val_loss: 0.2114 - val_binary_accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2493 - binary_accuracy: 1.0000 - val_loss: 0.2111 - val_binary_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2490 - binary_accuracy: 1.0000 - val_loss: 0.2107 - val_binary_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2487 - binary_accuracy: 1.0000 - val_loss: 0.2104 - val_binary_accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2483 - binary_accuracy: 1.0000 - val_loss: 0.2101 - val_binary_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2480 - binary_accuracy: 1.0000 - val_loss: 0.2098 - val_binary_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2477 - binary_accuracy: 1.0000 - val_loss: 0.2094 - val_binary_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2474 - binary_accuracy: 1.0000 - val_loss: 0.2091 - val_binary_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2470 - binary_accuracy: 1.0000 - val_loss: 0.2088 - val_binary_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2467 - binary_accuracy: 1.0000 - val_loss: 0.2085 - val_binary_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2464 - binary_accuracy: 1.0000 - val_loss: 0.2081 - val_binary_accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2460 - binary_accuracy: 1.0000 - val_loss: 0.2078 - val_binary_accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2457 - binary_accuracy: 1.0000 - val_loss: 0.2075 - val_binary_accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2454 - binary_accuracy: 1.0000 - val_loss: 0.2072 - val_binary_accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2451 - binary_accuracy: 1.0000 - val_loss: 0.2068 - val_binary_accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2448 - binary_accuracy: 1.0000 - val_loss: 0.2065 - val_binary_accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2444 - binary_accuracy: 1.0000 - val_loss: 0.2062 - val_binary_accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2441 - binary_accuracy: 1.0000 - val_loss: 0.2059 - val_binary_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2438 - binary_accuracy: 1.0000 - val_loss: 0.2056 - val_binary_accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2435 - binary_accuracy: 1.0000 - val_loss: 0.2053 - val_binary_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2431 - binary_accuracy: 1.0000 - val_loss: 0.2049 - val_binary_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2428 - binary_accuracy: 1.0000 - val_loss: 0.2046 - val_binary_accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2425 - binary_accuracy: 1.0000 - val_loss: 0.2043 - val_binary_accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2422 - binary_accuracy: 1.0000 - val_loss: 0.2040 - val_binary_accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2419 - binary_accuracy: 1.0000 - val_loss: 0.2037 - val_binary_accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2416 - binary_accuracy: 1.0000 - val_loss: 0.2034 - val_binary_accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2412 - binary_accuracy: 1.0000 - val_loss: 0.2030 - val_binary_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2409 - binary_accuracy: 1.0000 - val_loss: 0.2027 - val_binary_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2406 - binary_accuracy: 1.0000 - val_loss: 0.2024 - val_binary_accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2403 - binary_accuracy: 1.0000 - val_loss: 0.2021 - val_binary_accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2400 - binary_accuracy: 1.0000 - val_loss: 0.2018 - val_binary_accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2397 - binary_accuracy: 1.0000 - val_loss: 0.2015 - val_binary_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2394 - binary_accuracy: 1.0000 - val_loss: 0.2012 - val_binary_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2390 - binary_accuracy: 1.0000 - val_loss: 0.2009 - val_binary_accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2387 - binary_accuracy: 1.0000 - val_loss: 0.2006 - val_binary_accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2384 - binary_accuracy: 1.0000 - val_loss: 0.2003 - val_binary_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2381 - binary_accuracy: 1.0000 - val_loss: 0.2000 - val_binary_accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2378 - binary_accuracy: 1.0000 - val_loss: 0.1996 - val_binary_accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2375 - binary_accuracy: 1.0000 - val_loss: 0.1993 - val_binary_accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2372 - binary_accuracy: 1.0000 - val_loss: 0.1990 - val_binary_accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2369 - binary_accuracy: 1.0000 - val_loss: 0.1987 - val_binary_accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2366 - binary_accuracy: 1.0000 - val_loss: 0.1984 - val_binary_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2363 - binary_accuracy: 1.0000 - val_loss: 0.1981 - val_binary_accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2360 - binary_accuracy: 1.0000 - val_loss: 0.1978 - val_binary_accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2357 - binary_accuracy: 1.0000 - val_loss: 0.1975 - val_binary_accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2354 - binary_accuracy: 1.0000 - val_loss: 0.1972 - val_binary_accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2350 - binary_accuracy: 1.0000 - val_loss: 0.1969 - val_binary_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2347 - binary_accuracy: 1.0000 - val_loss: 0.1966 - val_binary_accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2344 - binary_accuracy: 1.0000 - val_loss: 0.1963 - val_binary_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2341 - binary_accuracy: 1.0000 - val_loss: 0.1960 - val_binary_accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2338 - binary_accuracy: 1.0000 - val_loss: 0.1957 - val_binary_accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2335 - binary_accuracy: 1.0000 - val_loss: 0.1954 - val_binary_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2332 - binary_accuracy: 1.0000 - val_loss: 0.1951 - val_binary_accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2329 - binary_accuracy: 1.0000 - val_loss: 0.1948 - val_binary_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2326 - binary_accuracy: 1.0000 - val_loss: 0.1946 - val_binary_accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2323 - binary_accuracy: 1.0000 - val_loss: 0.1943 - val_binary_accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2320 - binary_accuracy: 1.0000 - val_loss: 0.1940 - val_binary_accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2317 - binary_accuracy: 1.0000 - val_loss: 0.1937 - val_binary_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2314 - binary_accuracy: 1.0000 - val_loss: 0.1934 - val_binary_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2311 - binary_accuracy: 1.0000 - val_loss: 0.1931 - val_binary_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2309 - binary_accuracy: 1.0000 - val_loss: 0.1928 - val_binary_accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2306 - binary_accuracy: 1.0000 - val_loss: 0.1925 - val_binary_accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2303 - binary_accuracy: 1.0000 - val_loss: 0.1922 - val_binary_accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2300 - binary_accuracy: 1.0000 - val_loss: 0.1919 - val_binary_accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2297 - binary_accuracy: 1.0000 - val_loss: 0.1916 - val_binary_accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2294 - binary_accuracy: 1.0000 - val_loss: 0.1913 - val_binary_accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2292 - binary_accuracy: 1.0000 - val_loss: 0.1911 - val_binary_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2289 - binary_accuracy: 1.0000 - val_loss: 0.1908 - val_binary_accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2286 - binary_accuracy: 1.0000 - val_loss: 0.1905 - val_binary_accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2283 - binary_accuracy: 1.0000 - val_loss: 0.1902 - val_binary_accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2280 - binary_accuracy: 1.0000 - val_loss: 0.1899 - val_binary_accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2277 - binary_accuracy: 1.0000 - val_loss: 0.1896 - val_binary_accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2275 - binary_accuracy: 1.0000 - val_loss: 0.1893 - val_binary_accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2272 - binary_accuracy: 1.0000 - val_loss: 0.1891 - val_binary_accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2269 - binary_accuracy: 1.0000 - val_loss: 0.1888 - val_binary_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2266 - binary_accuracy: 1.0000 - val_loss: 0.1885 - val_binary_accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2264 - binary_accuracy: 1.0000 - val_loss: 0.1882 - val_binary_accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2261 - binary_accuracy: 1.0000 - val_loss: 0.1879 - val_binary_accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2258 - binary_accuracy: 1.0000 - val_loss: 0.1877 - val_binary_accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2255 - binary_accuracy: 1.0000 - val_loss: 0.1874 - val_binary_accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2253 - binary_accuracy: 1.0000 - val_loss: 0.1871 - val_binary_accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2250 - binary_accuracy: 1.0000 - val_loss: 0.1868 - val_binary_accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2247 - binary_accuracy: 1.0000 - val_loss: 0.1865 - val_binary_accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2244 - binary_accuracy: 1.0000 - val_loss: 0.1863 - val_binary_accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2242 - binary_accuracy: 1.0000 - val_loss: 0.1860 - val_binary_accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2239 - binary_accuracy: 1.0000 - val_loss: 0.1857 - val_binary_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2236 - binary_accuracy: 1.0000 - val_loss: 0.1854 - val_binary_accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2233 - binary_accuracy: 1.0000 - val_loss: 0.1852 - val_binary_accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2231 - binary_accuracy: 1.0000 - val_loss: 0.1849 - val_binary_accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2228 - binary_accuracy: 1.0000 - val_loss: 0.1846 - val_binary_accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2225 - binary_accuracy: 1.0000 - val_loss: 0.1843 - val_binary_accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2223 - binary_accuracy: 1.0000 - val_loss: 0.1841 - val_binary_accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2220 - binary_accuracy: 1.0000 - val_loss: 0.1838 - val_binary_accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2217 - binary_accuracy: 1.0000 - val_loss: 0.1835 - val_binary_accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2215 - binary_accuracy: 1.0000 - val_loss: 0.1832 - val_binary_accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2212 - binary_accuracy: 1.0000 - val_loss: 0.1830 - val_binary_accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2209 - binary_accuracy: 1.0000 - val_loss: 0.1827 - val_binary_accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2207 - binary_accuracy: 1.0000 - val_loss: 0.1824 - val_binary_accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2204 - binary_accuracy: 1.0000 - val_loss: 0.1822 - val_binary_accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2201 - binary_accuracy: 1.0000 - val_loss: 0.1819 - val_binary_accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2199 - binary_accuracy: 1.0000 - val_loss: 0.1816 - val_binary_accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2196 - binary_accuracy: 1.0000 - val_loss: 0.1814 - val_binary_accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2193 - binary_accuracy: 1.0000 - val_loss: 0.1811 - val_binary_accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2191 - binary_accuracy: 1.0000 - val_loss: 0.1808 - val_binary_accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2188 - binary_accuracy: 1.0000 - val_loss: 0.1806 - val_binary_accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2185 - binary_accuracy: 1.0000 - val_loss: 0.1803 - val_binary_accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2183 - binary_accuracy: 1.0000 - val_loss: 0.1800 - val_binary_accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2180 - binary_accuracy: 1.0000 - val_loss: 0.1798 - val_binary_accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2177 - binary_accuracy: 1.0000 - val_loss: 0.1795 - val_binary_accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2175 - binary_accuracy: 1.0000 - val_loss: 0.1792 - val_binary_accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2172 - binary_accuracy: 1.0000 - val_loss: 0.1790 - val_binary_accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2170 - binary_accuracy: 1.0000 - val_loss: 0.1787 - val_binary_accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2167 - binary_accuracy: 1.0000 - val_loss: 0.1784 - val_binary_accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2164 - binary_accuracy: 1.0000 - val_loss: 0.1782 - val_binary_accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2162 - binary_accuracy: 1.0000 - val_loss: 0.1779 - val_binary_accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2159 - binary_accuracy: 1.0000 - val_loss: 0.1777 - val_binary_accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2157 - binary_accuracy: 1.0000 - val_loss: 0.1774 - val_binary_accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2154 - binary_accuracy: 1.0000 - val_loss: 0.1771 - val_binary_accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2152 - binary_accuracy: 1.0000 - val_loss: 0.1769 - val_binary_accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2149 - binary_accuracy: 1.0000 - val_loss: 0.1766 - val_binary_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2146 - binary_accuracy: 1.0000 - val_loss: 0.1764 - val_binary_accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2144 - binary_accuracy: 1.0000 - val_loss: 0.1761 - val_binary_accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2141 - binary_accuracy: 1.0000 - val_loss: 0.1759 - val_binary_accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2139 - binary_accuracy: 1.0000 - val_loss: 0.1756 - val_binary_accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2136 - binary_accuracy: 1.0000 - val_loss: 0.1753 - val_binary_accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2134 - binary_accuracy: 1.0000 - val_loss: 0.1751 - val_binary_accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2131 - binary_accuracy: 1.0000 - val_loss: 0.1748 - val_binary_accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2129 - binary_accuracy: 1.0000 - val_loss: 0.1746 - val_binary_accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2126 - binary_accuracy: 1.0000 - val_loss: 0.1743 - val_binary_accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2124 - binary_accuracy: 1.0000 - val_loss: 0.1741 - val_binary_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2121 - binary_accuracy: 1.0000 - val_loss: 0.1738 - val_binary_accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2119 - binary_accuracy: 1.0000 - val_loss: 0.1736 - val_binary_accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2116 - binary_accuracy: 1.0000 - val_loss: 0.1733 - val_binary_accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2114 - binary_accuracy: 1.0000 - val_loss: 0.1731 - val_binary_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2111 - binary_accuracy: 1.0000 - val_loss: 0.1728 - val_binary_accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2109 - binary_accuracy: 1.0000 - val_loss: 0.1726 - val_binary_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2106 - binary_accuracy: 1.0000 - val_loss: 0.1723 - val_binary_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2104 - binary_accuracy: 1.0000 - val_loss: 0.1721 - val_binary_accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2101 - binary_accuracy: 1.0000 - val_loss: 0.1718 - val_binary_accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2099 - binary_accuracy: 1.0000 - val_loss: 0.1716 - val_binary_accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2096 - binary_accuracy: 1.0000 - val_loss: 0.1713 - val_binary_accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2094 - binary_accuracy: 1.0000 - val_loss: 0.1711 - val_binary_accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2091 - binary_accuracy: 1.0000 - val_loss: 0.1708 - val_binary_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2089 - binary_accuracy: 1.0000 - val_loss: 0.1706 - val_binary_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2086 - binary_accuracy: 1.0000 - val_loss: 0.1703 - val_binary_accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2084 - binary_accuracy: 1.0000 - val_loss: 0.1701 - val_binary_accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2082 - binary_accuracy: 1.0000 - val_loss: 0.1698 - val_binary_accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2079 - binary_accuracy: 1.0000 - val_loss: 0.1696 - val_binary_accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2077 - binary_accuracy: 1.0000 - val_loss: 0.1694 - val_binary_accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2074 - binary_accuracy: 1.0000 - val_loss: 0.1691 - val_binary_accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2072 - binary_accuracy: 1.0000 - val_loss: 0.1689 - val_binary_accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2069 - binary_accuracy: 1.0000 - val_loss: 0.1686 - val_binary_accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2067 - binary_accuracy: 1.0000 - val_loss: 0.1684 - val_binary_accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2065 - binary_accuracy: 1.0000 - val_loss: 0.1681 - val_binary_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2062 - binary_accuracy: 1.0000 - val_loss: 0.1679 - val_binary_accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2060 - binary_accuracy: 1.0000 - val_loss: 0.1677 - val_binary_accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2057 - binary_accuracy: 1.0000 - val_loss: 0.1674 - val_binary_accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2055 - binary_accuracy: 1.0000 - val_loss: 0.1672 - val_binary_accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2053 - binary_accuracy: 1.0000 - val_loss: 0.1669 - val_binary_accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2050 - binary_accuracy: 1.0000 - val_loss: 0.1667 - val_binary_accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2048 - binary_accuracy: 1.0000 - val_loss: 0.1665 - val_binary_accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2045 - binary_accuracy: 1.0000 - val_loss: 0.1662 - val_binary_accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2043 - binary_accuracy: 1.0000 - val_loss: 0.1660 - val_binary_accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2041 - binary_accuracy: 1.0000 - val_loss: 0.1658 - val_binary_accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2038 - binary_accuracy: 1.0000 - val_loss: 0.1655 - val_binary_accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2036 - binary_accuracy: 1.0000 - val_loss: 0.1653 - val_binary_accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2034 - binary_accuracy: 1.0000 - val_loss: 0.1650 - val_binary_accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2031 - binary_accuracy: 1.0000 - val_loss: 0.1648 - val_binary_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2029 - binary_accuracy: 1.0000 - val_loss: 0.1646 - val_binary_accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2027 - binary_accuracy: 1.0000 - val_loss: 0.1643 - val_binary_accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2024 - binary_accuracy: 1.0000 - val_loss: 0.1641 - val_binary_accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2022 - binary_accuracy: 1.0000 - val_loss: 0.1639 - val_binary_accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2020 - binary_accuracy: 1.0000 - val_loss: 0.1636 - val_binary_accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2017 - binary_accuracy: 1.0000 - val_loss: 0.1634 - val_binary_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2015 - binary_accuracy: 1.0000 - val_loss: 0.1632 - val_binary_accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2013 - binary_accuracy: 1.0000 - val_loss: 0.1629 - val_binary_accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2010 - binary_accuracy: 1.0000 - val_loss: 0.1627 - val_binary_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2008 - binary_accuracy: 1.0000 - val_loss: 0.1625 - val_binary_accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2006 - binary_accuracy: 1.0000 - val_loss: 0.1622 - val_binary_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2003 - binary_accuracy: 1.0000 - val_loss: 0.1620 - val_binary_accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2001 - binary_accuracy: 1.0000 - val_loss: 0.1618 - val_binary_accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1999 - binary_accuracy: 1.0000 - val_loss: 0.1616 - val_binary_accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1996 - binary_accuracy: 1.0000 - val_loss: 0.1613 - val_binary_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1994 - binary_accuracy: 1.0000 - val_loss: 0.1611 - val_binary_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1992 - binary_accuracy: 1.0000 - val_loss: 0.1609 - val_binary_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1989 - binary_accuracy: 1.0000 - val_loss: 0.1606 - val_binary_accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1987 - binary_accuracy: 1.0000 - val_loss: 0.1604 - val_binary_accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1985 - binary_accuracy: 1.0000 - val_loss: 0.1602 - val_binary_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1983 - binary_accuracy: 1.0000 - val_loss: 0.1600 - val_binary_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1980 - binary_accuracy: 1.0000 - val_loss: 0.1597 - val_binary_accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1978 - binary_accuracy: 1.0000 - val_loss: 0.1595 - val_binary_accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1976 - binary_accuracy: 1.0000 - val_loss: 0.1593 - val_binary_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1974 - binary_accuracy: 1.0000 - val_loss: 0.1591 - val_binary_accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1971 - binary_accuracy: 1.0000 - val_loss: 0.1588 - val_binary_accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1969 - binary_accuracy: 1.0000 - val_loss: 0.1586 - val_binary_accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1967 - binary_accuracy: 1.0000 - val_loss: 0.1584 - val_binary_accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1964 - binary_accuracy: 1.0000 - val_loss: 0.1582 - val_binary_accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1962 - binary_accuracy: 1.0000 - val_loss: 0.1579 - val_binary_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1960 - binary_accuracy: 1.0000 - val_loss: 0.1577 - val_binary_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1958 - binary_accuracy: 1.0000 - val_loss: 0.1575 - val_binary_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1956 - binary_accuracy: 1.0000 - val_loss: 0.1573 - val_binary_accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1953 - binary_accuracy: 1.0000 - val_loss: 0.1571 - val_binary_accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1951 - binary_accuracy: 1.0000 - val_loss: 0.1568 - val_binary_accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1949 - binary_accuracy: 1.0000 - val_loss: 0.1566 - val_binary_accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1947 - binary_accuracy: 1.0000 - val_loss: 0.1564 - val_binary_accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1944 - binary_accuracy: 1.0000 - val_loss: 0.1562 - val_binary_accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1942 - binary_accuracy: 1.0000 - val_loss: 0.1560 - val_binary_accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1940 - binary_accuracy: 1.0000 - val_loss: 0.1557 - val_binary_accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1938 - binary_accuracy: 1.0000 - val_loss: 0.1555 - val_binary_accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1936 - binary_accuracy: 1.0000 - val_loss: 0.1553 - val_binary_accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1933 - binary_accuracy: 1.0000 - val_loss: 0.1551 - val_binary_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1931 - binary_accuracy: 1.0000 - val_loss: 0.1549 - val_binary_accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1929 - binary_accuracy: 1.0000 - val_loss: 0.1547 - val_binary_accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1927 - binary_accuracy: 1.0000 - val_loss: 0.1544 - val_binary_accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1925 - binary_accuracy: 1.0000 - val_loss: 0.1542 - val_binary_accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1922 - binary_accuracy: 1.0000 - val_loss: 0.1540 - val_binary_accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1920 - binary_accuracy: 1.0000 - val_loss: 0.1538 - val_binary_accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1918 - binary_accuracy: 1.0000 - val_loss: 0.1536 - val_binary_accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1916 - binary_accuracy: 1.0000 - val_loss: 0.1534 - val_binary_accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1914 - binary_accuracy: 1.0000 - val_loss: 0.1531 - val_binary_accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1912 - binary_accuracy: 1.0000 - val_loss: 0.1529 - val_binary_accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1909 - binary_accuracy: 1.0000 - val_loss: 0.1527 - val_binary_accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1907 - binary_accuracy: 1.0000 - val_loss: 0.1525 - val_binary_accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1905 - binary_accuracy: 1.0000 - val_loss: 0.1523 - val_binary_accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1903 - binary_accuracy: 1.0000 - val_loss: 0.1521 - val_binary_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1901 - binary_accuracy: 1.0000 - val_loss: 0.1519 - val_binary_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1899 - binary_accuracy: 1.0000 - val_loss: 0.1517 - val_binary_accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1897 - binary_accuracy: 1.0000 - val_loss: 0.1514 - val_binary_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1894 - binary_accuracy: 1.0000 - val_loss: 0.1512 - val_binary_accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1892 - binary_accuracy: 1.0000 - val_loss: 0.1510 - val_binary_accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1890 - binary_accuracy: 1.0000 - val_loss: 0.1508 - val_binary_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1888 - binary_accuracy: 1.0000 - val_loss: 0.1506 - val_binary_accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1886 - binary_accuracy: 1.0000 - val_loss: 0.1504 - val_binary_accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1884 - binary_accuracy: 1.0000 - val_loss: 0.1502 - val_binary_accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1882 - binary_accuracy: 1.0000 - val_loss: 0.1500 - val_binary_accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1880 - binary_accuracy: 1.0000 - val_loss: 0.1498 - val_binary_accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1877 - binary_accuracy: 1.0000 - val_loss: 0.1496 - val_binary_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1875 - binary_accuracy: 1.0000 - val_loss: 0.1494 - val_binary_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1873 - binary_accuracy: 1.0000 - val_loss: 0.1492 - val_binary_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1871 - binary_accuracy: 1.0000 - val_loss: 0.1489 - val_binary_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1869 - binary_accuracy: 1.0000 - val_loss: 0.1487 - val_binary_accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1867 - binary_accuracy: 1.0000 - val_loss: 0.1485 - val_binary_accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1865 - binary_accuracy: 1.0000 - val_loss: 0.1483 - val_binary_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1863 - binary_accuracy: 1.0000 - val_loss: 0.1481 - val_binary_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1861 - binary_accuracy: 1.0000 - val_loss: 0.1479 - val_binary_accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1859 - binary_accuracy: 1.0000 - val_loss: 0.1477 - val_binary_accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1856 - binary_accuracy: 1.0000 - val_loss: 0.1475 - val_binary_accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1854 - binary_accuracy: 1.0000 - val_loss: 0.1473 - val_binary_accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1852 - binary_accuracy: 1.0000 - val_loss: 0.1471 - val_binary_accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1850 - binary_accuracy: 1.0000 - val_loss: 0.1469 - val_binary_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1848 - binary_accuracy: 1.0000 - val_loss: 0.1467 - val_binary_accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1846 - binary_accuracy: 1.0000 - val_loss: 0.1465 - val_binary_accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1844 - binary_accuracy: 1.0000 - val_loss: 0.1463 - val_binary_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1842 - binary_accuracy: 1.0000 - val_loss: 0.1461 - val_binary_accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1840 - binary_accuracy: 1.0000 - val_loss: 0.1459 - val_binary_accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1838 - binary_accuracy: 1.0000 - val_loss: 0.1457 - val_binary_accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1836 - binary_accuracy: 1.0000 - val_loss: 0.1455 - val_binary_accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1834 - binary_accuracy: 1.0000 - val_loss: 0.1453 - val_binary_accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1832 - binary_accuracy: 1.0000 - val_loss: 0.1451 - val_binary_accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1830 - binary_accuracy: 1.0000 - val_loss: 0.1449 - val_binary_accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1828 - binary_accuracy: 1.0000 - val_loss: 0.1447 - val_binary_accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1826 - binary_accuracy: 1.0000 - val_loss: 0.1445 - val_binary_accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1824 - binary_accuracy: 1.0000 - val_loss: 0.1443 - val_binary_accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1822 - binary_accuracy: 1.0000 - val_loss: 0.1441 - val_binary_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1820 - binary_accuracy: 1.0000 - val_loss: 0.1439 - val_binary_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1818 - binary_accuracy: 1.0000 - val_loss: 0.1437 - val_binary_accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1816 - binary_accuracy: 1.0000 - val_loss: 0.1435 - val_binary_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1814 - binary_accuracy: 1.0000 - val_loss: 0.1433 - val_binary_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1812 - binary_accuracy: 1.0000 - val_loss: 0.1431 - val_binary_accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1810 - binary_accuracy: 1.0000 - val_loss: 0.1429 - val_binary_accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1808 - binary_accuracy: 1.0000 - val_loss: 0.1427 - val_binary_accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1806 - binary_accuracy: 1.0000 - val_loss: 0.1425 - val_binary_accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1804 - binary_accuracy: 1.0000 - val_loss: 0.1423 - val_binary_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1802 - binary_accuracy: 1.0000 - val_loss: 0.1421 - val_binary_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1800 - binary_accuracy: 1.0000 - val_loss: 0.1420 - val_binary_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1798 - binary_accuracy: 1.0000 - val_loss: 0.1418 - val_binary_accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1796 - binary_accuracy: 1.0000 - val_loss: 0.1416 - val_binary_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1794 - binary_accuracy: 1.0000 - val_loss: 0.1414 - val_binary_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1792 - binary_accuracy: 1.0000 - val_loss: 0.1412 - val_binary_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1790 - binary_accuracy: 1.0000 - val_loss: 0.1410 - val_binary_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1788 - binary_accuracy: 1.0000 - val_loss: 0.1408 - val_binary_accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1786 - binary_accuracy: 1.0000 - val_loss: 0.1406 - val_binary_accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1784 - binary_accuracy: 1.0000 - val_loss: 0.1404 - val_binary_accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1782 - binary_accuracy: 1.0000 - val_loss: 0.1402 - val_binary_accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1780 - binary_accuracy: 1.0000 - val_loss: 0.1400 - val_binary_accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1778 - binary_accuracy: 1.0000 - val_loss: 0.1398 - val_binary_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1776 - binary_accuracy: 1.0000 - val_loss: 0.1396 - val_binary_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1774 - binary_accuracy: 1.0000 - val_loss: 0.1395 - val_binary_accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1772 - binary_accuracy: 1.0000 - val_loss: 0.1393 - val_binary_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1770 - binary_accuracy: 1.0000 - val_loss: 0.1391 - val_binary_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1768 - binary_accuracy: 1.0000 - val_loss: 0.1389 - val_binary_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1766 - binary_accuracy: 1.0000 - val_loss: 0.1387 - val_binary_accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1764 - binary_accuracy: 1.0000 - val_loss: 0.1385 - val_binary_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1762 - binary_accuracy: 1.0000 - val_loss: 0.1383 - val_binary_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1760 - binary_accuracy: 1.0000 - val_loss: 0.1381 - val_binary_accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1758 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1757 - binary_accuracy: 1.0000 - val_loss: 0.1378 - val_binary_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1755 - binary_accuracy: 1.0000 - val_loss: 0.1376 - val_binary_accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1753 - binary_accuracy: 1.0000 - val_loss: 0.1374 - val_binary_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1751 - binary_accuracy: 1.0000 - val_loss: 0.1372 - val_binary_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1749 - binary_accuracy: 1.0000 - val_loss: 0.1370 - val_binary_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1747 - binary_accuracy: 1.0000 - val_loss: 0.1368 - val_binary_accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1745 - binary_accuracy: 1.0000 - val_loss: 0.1367 - val_binary_accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1743 - binary_accuracy: 1.0000 - val_loss: 0.1365 - val_binary_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1741 - binary_accuracy: 1.0000 - val_loss: 0.1363 - val_binary_accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1739 - binary_accuracy: 1.0000 - val_loss: 0.1361 - val_binary_accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1737 - binary_accuracy: 1.0000 - val_loss: 0.1359 - val_binary_accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1736 - binary_accuracy: 1.0000 - val_loss: 0.1357 - val_binary_accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1734 - binary_accuracy: 1.0000 - val_loss: 0.1356 - val_binary_accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1732 - binary_accuracy: 1.0000 - val_loss: 0.1354 - val_binary_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1730 - binary_accuracy: 1.0000 - val_loss: 0.1352 - val_binary_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1728 - binary_accuracy: 1.0000 - val_loss: 0.1350 - val_binary_accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1726 - binary_accuracy: 1.0000 - val_loss: 0.1348 - val_binary_accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1724 - binary_accuracy: 1.0000 - val_loss: 0.1346 - val_binary_accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1722 - binary_accuracy: 1.0000 - val_loss: 0.1345 - val_binary_accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1721 - binary_accuracy: 1.0000 - val_loss: 0.1343 - val_binary_accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1719 - binary_accuracy: 1.0000 - val_loss: 0.1341 - val_binary_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1717 - binary_accuracy: 1.0000 - val_loss: 0.1339 - val_binary_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1715 - binary_accuracy: 1.0000 - val_loss: 0.1337 - val_binary_accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1713 - binary_accuracy: 1.0000 - val_loss: 0.1336 - val_binary_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1711 - binary_accuracy: 1.0000 - val_loss: 0.1334 - val_binary_accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1709 - binary_accuracy: 1.0000 - val_loss: 0.1332 - val_binary_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1708 - binary_accuracy: 1.0000 - val_loss: 0.1330 - val_binary_accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1706 - binary_accuracy: 1.0000 - val_loss: 0.1328 - val_binary_accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1704 - binary_accuracy: 1.0000 - val_loss: 0.1327 - val_binary_accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1702 - binary_accuracy: 1.0000 - val_loss: 0.1325 - val_binary_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1700 - binary_accuracy: 1.0000 - val_loss: 0.1323 - val_binary_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1698 - binary_accuracy: 1.0000 - val_loss: 0.1321 - val_binary_accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1696 - binary_accuracy: 1.0000 - val_loss: 0.1320 - val_binary_accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1695 - binary_accuracy: 1.0000 - val_loss: 0.1318 - val_binary_accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1693 - binary_accuracy: 1.0000 - val_loss: 0.1316 - val_binary_accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1691 - binary_accuracy: 1.0000 - val_loss: 0.1314 - val_binary_accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1689 - binary_accuracy: 1.0000 - val_loss: 0.1313 - val_binary_accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1687 - binary_accuracy: 1.0000 - val_loss: 0.1311 - val_binary_accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1686 - binary_accuracy: 1.0000 - val_loss: 0.1309 - val_binary_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1684 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1682 - binary_accuracy: 1.0000 - val_loss: 0.1306 - val_binary_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1680 - binary_accuracy: 1.0000 - val_loss: 0.1304 - val_binary_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1678 - binary_accuracy: 1.0000 - val_loss: 0.1302 - val_binary_accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1676 - binary_accuracy: 1.0000 - val_loss: 0.1300 - val_binary_accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1675 - binary_accuracy: 1.0000 - val_loss: 0.1299 - val_binary_accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1673 - binary_accuracy: 1.0000 - val_loss: 0.1297 - val_binary_accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1671 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1669 - binary_accuracy: 1.0000 - val_loss: 0.1293 - val_binary_accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1667 - binary_accuracy: 1.0000 - val_loss: 0.1292 - val_binary_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1666 - binary_accuracy: 1.0000 - val_loss: 0.1290 - val_binary_accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1664 - binary_accuracy: 1.0000 - val_loss: 0.1288 - val_binary_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1662 - binary_accuracy: 1.0000 - val_loss: 0.1287 - val_binary_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1660 - binary_accuracy: 1.0000 - val_loss: 0.1285 - val_binary_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1659 - binary_accuracy: 1.0000 - val_loss: 0.1283 - val_binary_accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1657 - binary_accuracy: 1.0000 - val_loss: 0.1282 - val_binary_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1655 - binary_accuracy: 1.0000 - val_loss: 0.1280 - val_binary_accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1653 - binary_accuracy: 1.0000 - val_loss: 0.1278 - val_binary_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1651 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1650 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1648 - binary_accuracy: 1.0000 - val_loss: 0.1273 - val_binary_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1646 - binary_accuracy: 1.0000 - val_loss: 0.1271 - val_binary_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1644 - binary_accuracy: 1.0000 - val_loss: 0.1270 - val_binary_accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1643 - binary_accuracy: 1.0000 - val_loss: 0.1268 - val_binary_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1641 - binary_accuracy: 1.0000 - val_loss: 0.1266 - val_binary_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1639 - binary_accuracy: 1.0000 - val_loss: 0.1265 - val_binary_accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1637 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1636 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1634 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1632 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1630 - binary_accuracy: 1.0000 - val_loss: 0.1256 - val_binary_accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1629 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1627 - binary_accuracy: 1.0000 - val_loss: 0.1253 - val_binary_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1625 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1624 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1622 - binary_accuracy: 1.0000 - val_loss: 0.1248 - val_binary_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1620 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1618 - binary_accuracy: 1.0000 - val_loss: 0.1245 - val_binary_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1617 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1615 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1613 - binary_accuracy: 1.0000 - val_loss: 0.1240 - val_binary_accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1612 - binary_accuracy: 1.0000 - val_loss: 0.1238 - val_binary_accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1610 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1608 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1606 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1605 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1603 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1601 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1600 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1598 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1596 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1595 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1593 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1591 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1590 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1588 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1586 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1585 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1583 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1581 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1580 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1578 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1576 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1575 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1573 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1571 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1570 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1568 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1566 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1565 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1563 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1561 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1560 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1558 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1557 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1555 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1553 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1552 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1550 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1548 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1547 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1545 - binary_accuracy: 1.0000 - val_loss: 0.1175 - val_binary_accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1544 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1542 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1540 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1539 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1537 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1536 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1534 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1532 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1531 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1529 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1528 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1526 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1525 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1523 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1521 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1520 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1518 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1517 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1515 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1512 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1510 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1509 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1507 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1506 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fe0058390>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, np.array(y_train), validation_split=.1, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_model2 = model2.predict([np.array(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predictions_model2:\n",
    "    i[0] = i[0]*10\n",
    "\n",
    "for i in predictions_model2:\n",
    "    if i[0]>0.5:\n",
    "        i[0]=1\n",
    "    else:\n",
    "        i[0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181818181818182"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions_rf, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0],\n",
       "       [2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, predictions_rf)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\dhani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\dhani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydot) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\dhani\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\dhani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.1 MB 445.2 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.2/2.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.6/2.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\dhani\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.20.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\dhani\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model1,to_file=\"Model1_plot\",show_shapes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
